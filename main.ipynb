{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_WIDTH = 192\n",
    "RESIZE_HEIGHT = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDarker(A.ImageOnlyTransform):\n",
    "    def __init__(self, max_dark, max_bright, always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply=always_apply, p=p)  # Pass 'p' to parent\n",
    "        self.max_dark = max_dark\n",
    "        self.max_bright = max_bright\n",
    "\n",
    "    def apply(self, image, **params):\n",
    "        # Randomly choose a darkening factor between max_dark and max_bright\n",
    "        factor = 1 + np.random.uniform(self.max_dark, self.max_bright)\n",
    "        # Apply the factor to darken the image\n",
    "        image = image * factor\n",
    "        # Clip values to ensure they stay within valid range [0, 255]\n",
    "        image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.Rotate(limit=10, border_mode=cv2.BORDER_REFLECT, p=1),\n",
    "    A.RandomScale(scale_limit=0.1, p=0.2),\n",
    "    A.OneOf([\n",
    "        CustomDarker(max_dark=-0.4, max_bright=-0.1, p=0.5),\n",
    "        CustomDarker(max_dark=-0.2, max_bright=0.0, p=0.25),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.25),\n",
    "    ], p=0.5),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3, p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3, 5), p=0.4),\n",
    "    ], p=0.2),\n",
    "    A.ISONoise(p=0.15),\n",
    "    A.Perspective(p=0.15),\n",
    "    A.CoarseDropout(num_holes_range=(1, 1), hole_width_range=(16, 48), hole_height_range=(16, 48), p=0.2),\n",
    "    A.Resize(width=RESIZE_WIDTH, height=RESIZE_HEIGHT, p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggressive augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.Affine(scale=(0.8, 1.2), translate_percent=(0.1, 0.1), \\\n",
    "             rotate=(-30, 30),  border_mode=cv2.BORDER_CONSTANT, fit_output=False, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.4),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=7, p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "    ], p=0.3),\n",
    "    A.CoarseDropout(num_holes_range=(2, 4), hole_height_range=(32, 32),\\\n",
    "                     hole_width_range=(32, 32), p=0.15),\n",
    "    A.Perspective(scale=(0.05, 0.15), p=0.3),\n",
    "    A.RandomShadow(p=0.2),\n",
    "    A.ISONoise(p=0.2),\n",
    "    A.Sharpen(p=0.3),\n",
    "    A.Resize(width=RESIZE_WIDTH, height=RESIZE_HEIGHT, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_pipeline = A.Compose([\n",
    "    A.ToGray(p=1.0),\n",
    "    A.Sharpen(alpha=(0.2, 0.5), p=0.7),  \n",
    "    A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
    "    A.Affine(scale=(0.9, 1.1), translate_percent=(0.05, 0.05), rotate=(-15, 15), p=0.5),\n",
    "    A.Perspective(scale=(0.05, 0.15), p=0.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=0.3),\n",
    "    A.CoarseDropout(num_holes_range=(2, 4), hole_height_range=(16, 32),\\\n",
    "                    hole_width_range=(16, 32), p=0.2),\n",
    "    A.Resize(width=RESIZE_WIDTH, height=RESIZE_HEIGHT),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(image, num_augments=6):\n",
    "    augmented_images = []\n",
    "    for _ in range(num_augments):\n",
    "        augmented = augmentation_pipeline(image=image)['image']\n",
    "        augmented_images.append(augmented)\n",
    "\n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preview for minere_196.jpg to preview_augmented/minere\\minere_196_preview.png\n",
      "Saved preview for minere_263.jpg to preview_augmented/minere\\minere_263_preview.png\n",
      "Saved preview for minere_65.jpg to preview_augmented/minere\\minere_65_preview.png\n",
      "Saved preview for minere_208.jpg to preview_augmented/minere\\minere_208_preview.png\n",
      "Saved preview for minere_124.jpg to preview_augmented/minere\\minere_124_preview.png\n",
      "Previews generated for minere 🔥\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "def preview_augment(image, num_augments=4):\n",
    "    augmented_images = []\n",
    "    for _ in range(num_augments):\n",
    "        augmented = augmentation_pipeline(image=image)['image']\n",
    "        augmented_images.append(augmented)\n",
    "    \n",
    "    return augmented_images\n",
    "\n",
    "def get_and_preview_augmentation(dataset_path, class_name, sample_count=3):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    image_dir = f\"{dataset_path}/{class_name}\"\n",
    "    preview_dir = f\"preview_augmented/{class_name}\"\n",
    "    os.makedirs(preview_dir, exist_ok=True)\n",
    "    \n",
    "    # Get a list of all images in the directory\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    # Take a sample of the images\n",
    "    if len(image_files) > sample_count:\n",
    "        image_files = random.sample(image_files, sample_count)\n",
    "    \n",
    "    for idx, filename in enumerate(image_files):\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize for preview\n",
    "        preview_image = cv2.resize(image, (RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "        \n",
    "        # Generate augmented versions\n",
    "        augmented_images = preview_augment(preview_image, num_augments=4)\n",
    "        \n",
    "        # Create a figure for visualization\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        gs = gridspec.GridSpec(2, 3)\n",
    "        \n",
    "        # Display original image\n",
    "        ax = plt.subplot(gs[0, 0])\n",
    "        ax.imshow(preview_image)\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Display augmented images\n",
    "        for i, aug_img in enumerate(augmented_images):\n",
    "            row, col = (i+1) // 3, (i+1) % 3\n",
    "            ax = plt.subplot(gs[row, col])\n",
    "            \n",
    "            # Convert tensor to numpy if needed\n",
    "            if hasattr(aug_img, 'permute'):\n",
    "                aug_img = aug_img.permute(1, 2, 0).numpy()\n",
    "                \n",
    "            ax.imshow(aug_img)\n",
    "            ax.set_title(f'Augmented {i+1}')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        # Save the figure\n",
    "        output_path = os.path.join(preview_dir, f\"{filename.split('.')[0]}_preview.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved preview for {filename} to {output_path}\")\n",
    "    \n",
    "    print(f\"Previews generated for {class_name} 🔥\")\n",
    "\n",
    "get_and_preview_augmentation(\"dataset\", \"minere\", sample_count=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Config: Workers=8, Chunk=2, SafeMode=True\n",
      "🚀 Starting SAFE augmentation...\n",
      "🔥 Starting aura (330 images)\n",
      "🔥 Starting minere (330 images)\n",
      "🔥 Starting montfleur (330 images)\n",
      "📤 Loading aura_1.jpg...\n",
      "📤 Loading aura_10.jpg...\n",
      "📤 Loading aura_100.jpg...\n",
      "📤 Loading aura_101.jpg...\n",
      "📤 Loading aura_102.jpg...\n",
      "📤 Loading aura_103.jpg...\n",
      "📤 Loading aura_104.jpg...\n",
      "📤 Loading aura_105.jpg...\n",
      "📤 Loading minere_1.jpg...\n",
      "📤 Loading minere_10.jpg...\n",
      "📤 Loading minere_100.jpg...\n",
      "📤 Loading minere_101.jpg...\n",
      "📤 Loading minere_102.jpg...\n",
      "📤 Loading minere_103.jpg...\n",
      "📤 Loading minere_104.jpg...\n",
      "📤 Loading minere_105.jpg...\n",
      "✅ Completed batch 1\n",
      "📤 Loading montfleur_1.jpg...\n",
      "📤 Loading montfleur_10.jpg...\n",
      "📤 Loading montfleur_100.jpg...\n",
      "📤 Loading montfleur_101.jpg...\n",
      "📤 Loading montfleur_102.jpg...\n",
      "📤 Loading montfleur_103.jpg...\n",
      "📤 Loading montfleur_104.jpg...\n",
      "📤 Loading montfleur_105.jpg...\n",
      "📤 Loading aura_106.jpg...\n",
      "✅ Completed batch 1\n",
      "📤 Loading aura_107.jpg...\n",
      "📤 Loading aura_108.jpg...\n",
      "📤 Loading aura_109.jpg...\n",
      "📤 Loading aura_11.jpg...\n",
      "📤 Loading aura_110.jpg...\n",
      "📤 Loading aura_111.jpg...\n",
      "📤 Loading aura_112.jpg...\n",
      "✅ Completed batch 1\n",
      "📤 Loading minere_106.jpg...\n",
      "📤 Loading minere_107.jpg...\n",
      "📤 Loading minere_108.jpg...\n",
      "📤 Loading minere_109.jpg...\n",
      "📤 Loading minere_11.jpg...\n",
      "📤 Loading minere_110.jpg...\n",
      "📤 Loading minere_111.jpg...\n",
      "📤 Loading minere_112.jpg...\n",
      "📤 Loading montfleur_106.jpg...\n",
      "📤 Loading montfleur_107.jpg...\n",
      "📤 Loading montfleur_108.jpg...\n",
      "✅ Completed batch 2\n",
      "📤 Loading montfleur_109.jpg...\n",
      "📤 Loading montfleur_11.jpg...\n",
      "📤 Loading montfleur_110.jpg...\n",
      "📤 Loading montfleur_111.jpg...\n",
      "📤 Loading montfleur_112.jpg...\n",
      "✅ Completed batch 2\n",
      "📤 Loading aura_113.jpg...\n",
      "📤 Loading aura_114.jpg...\n",
      "📤 Loading aura_115.jpg...\n",
      "📤 Loading aura_116.jpg...\n",
      "📤 Loading aura_117.jpg...\n",
      "📤 Loading aura_118.jpg...\n",
      "📤 Loading aura_119.jpg...\n",
      "📤 Loading aura_12.jpg...\n",
      "📤 Loading minere_113.jpg...\n",
      "✅ Completed batch 2\n",
      "📤 Loading minere_114.jpg...\n",
      "📤 Loading minere_115.jpg...\n",
      "📤 Loading minere_116.jpg...\n",
      "📤 Loading minere_117.jpg...\n",
      "📤 Loading minere_118.jpg...\n",
      "📤 Loading minere_119.jpg...\n",
      "📤 Loading minere_12.jpg...\n",
      "✅ Completed batch 3\n",
      "📤 Loading montfleur_113.jpg...\n",
      "📤 Loading montfleur_114.jpg...\n",
      "📤 Loading montfleur_115.jpg...\n",
      "📤 Loading montfleur_116.jpg...\n",
      "📤 Loading montfleur_117.jpg...\n",
      "📤 Loading montfleur_118.jpg...\n",
      "📤 Loading montfleur_119.jpg...\n",
      "📤 Loading montfleur_12.jpg...\n",
      "📤 Loading aura_120.jpg...\n",
      "✅ Completed batch 3\n",
      "📤 Loading aura_121.jpg...\n",
      "📤 Loading aura_122.jpg...\n",
      "📤 Loading aura_123.jpg...\n",
      "📤 Loading aura_124.jpg...\n",
      "📤 Loading aura_125.jpg...\n",
      "📤 Loading aura_126.jpg...\n",
      "📤 Loading aura_127.jpg...\n",
      "📤 Loading minere_120.jpg...\n",
      "✅ Completed batch 3\n",
      "📤 Loading minere_121.jpg...\n",
      "📤 Loading minere_122.jpg...\n",
      "📤 Loading minere_123.jpg...\n",
      "📤 Loading minere_124.jpg...\n",
      "📤 Loading minere_125.jpg...\n",
      "📤 Loading minere_126.jpg...\n",
      "📤 Loading minere_127.jpg...\n",
      "✅ Completed batch 4\n",
      "📤 Loading montfleur_120.jpg...\n",
      "📤 Loading montfleur_121.jpg...\n",
      "📤 Loading montfleur_122.jpg...\n",
      "📤 Loading montfleur_123.jpg...\n",
      "📤 Loading montfleur_124.jpg...\n",
      "📤 Loading montfleur_125.jpg...\n",
      "📤 Loading montfleur_126.jpg...\n",
      "📤 Loading montfleur_127.jpg...\n",
      "📤 Loading aura_128.jpg...\n",
      "📤 Loading aura_129.jpg...\n",
      "✅ Completed batch 4\n",
      "📤 Loading aura_13.jpg...\n",
      "📤 Loading aura_130.jpg...\n",
      "📤 Loading aura_131.jpg...\n",
      "📤 Loading aura_132.jpg...\n",
      "📤 Loading aura_133.jpg...\n",
      "📤 Loading aura_134.jpg...\n",
      "📤 Loading minere_128.jpg...\n",
      "📤 Loading minere_129.jpg...\n",
      "✅ Completed batch 4\n",
      "📤 Loading minere_13.jpg...\n",
      "📤 Loading minere_130.jpg...\n",
      "📤 Loading minere_131.jpg...\n",
      "📤 Loading minere_132.jpg...\n",
      "📤 Loading minere_133.jpg...\n",
      "📤 Loading minere_134.jpg...\n",
      "✅ Completed batch 5\n",
      "📤 Loading montfleur_128.jpg...\n",
      "📤 Loading montfleur_129.jpg...\n",
      "📤 Loading montfleur_13.jpg...\n",
      "📤 Loading montfleur_130.jpg...\n",
      "📤 Loading montfleur_131.jpg...\n",
      "📤 Loading montfleur_132.jpg...\n",
      "📤 Loading montfleur_133.jpg...\n",
      "📤 Loading montfleur_134.jpg...\n",
      "📤 Loading aura_135.jpg...\n",
      "📤 Loading aura_136.jpg...\n",
      "✅ Completed batch 5\n",
      "📤 Loading aura_137.jpg...\n",
      "📤 Loading aura_138.jpg...\n",
      "📤 Loading aura_139.jpg...\n",
      "📤 Loading aura_14.jpg...\n",
      "📤 Loading aura_140.jpg...\n",
      "📤 Loading aura_141.jpg...\n",
      "✅ Completed batch 5\n",
      "📤 Loading minere_135.jpg...\n",
      "📤 Loading minere_136.jpg...\n",
      "📤 Loading minere_137.jpg...\n",
      "📤 Loading minere_138.jpg...\n",
      "📤 Loading minere_139.jpg...\n",
      "📤 Loading minere_14.jpg...\n",
      "📤 Loading minere_140.jpg...\n",
      "📤 Loading minere_141.jpg...\n",
      "✅ Completed batch 6\n",
      "📤 Loading montfleur_135.jpg...\n",
      "📤 Loading montfleur_136.jpg...\n",
      "📤 Loading montfleur_137.jpg...\n",
      "📤 Loading montfleur_138.jpg...\n",
      "📤 Loading montfleur_139.jpg...\n",
      "📤 Loading montfleur_14.jpg...\n",
      "📤 Loading montfleur_140.jpg...\n",
      "📤 Loading montfleur_141.jpg...\n",
      "📤 Loading aura_142.jpg...\n",
      "✅ Completed batch 6\n",
      "📤 Loading aura_143.jpg...\n",
      "📤 Loading aura_144.jpg...\n",
      "📤 Loading aura_145.jpg...\n",
      "📤 Loading aura_146.jpg...\n",
      "📤 Loading aura_147.jpg...\n",
      "📤 Loading aura_148.jpg...\n",
      "📤 Loading aura_149.jpg...\n",
      "📤 Loading minere_142.jpg...\n",
      "📤 Loading minere_143.jpg...\n",
      "✅ Completed batch 6\n",
      "📤 Loading minere_144.jpg...\n",
      "📤 Loading minere_145.jpg...\n",
      "📤 Loading minere_146.jpg...\n",
      "📤 Loading minere_147.jpg...\n",
      "📤 Loading minere_148.jpg...\n",
      "📤 Loading minere_149.jpg...\n",
      "📤 Loading montfleur_142.jpg...\n",
      "📤 Loading montfleur_143.jpg...\n",
      "📤 Loading montfleur_144.jpg...\n",
      "✅ Completed batch 7\n",
      "📤 Loading montfleur_145.jpg...\n",
      "📤 Loading montfleur_146.jpg...\n",
      "📤 Loading montfleur_147.jpg...\n",
      "📤 Loading montfleur_148.jpg...\n",
      "📤 Loading montfleur_149.jpg...\n",
      "📤 Loading aura_15.jpg...\n",
      "✅ Completed batch 7\n",
      "📤 Loading aura_150.jpg...\n",
      "📤 Loading aura_151.jpg...\n",
      "📤 Loading aura_152.jpg...\n",
      "📤 Loading aura_153.jpg...\n",
      "📤 Loading aura_154.jpg...\n",
      "📤 Loading aura_155.jpg...\n",
      "📤 Loading aura_156.jpg...\n",
      "✅ Completed batch 7\n",
      "📤 Loading minere_15.jpg...\n",
      "📤 Loading minere_150.jpg...\n",
      "📤 Loading minere_151.jpg...\n",
      "📤 Loading minere_152.jpg...\n",
      "📤 Loading minere_153.jpg...\n",
      "📤 Loading minere_154.jpg...\n",
      "📤 Loading minere_155.jpg...\n",
      "📤 Loading minere_156.jpg...\n",
      "✅ Completed batch 8\n",
      "📤 Loading montfleur_15.jpg...\n",
      "📤 Loading montfleur_150.jpg...\n",
      "📤 Loading montfleur_151.jpg...\n",
      "📤 Loading montfleur_152.jpg...\n",
      "📤 Loading montfleur_153.jpg...\n",
      "📤 Loading montfleur_154.jpg...\n",
      "📤 Loading montfleur_155.jpg...\n",
      "📤 Loading montfleur_156.jpg...\n",
      "✅ Completed batch 8\n",
      "📤 Loading aura_157.jpg...\n",
      "📤 Loading aura_158.jpg...\n",
      "📤 Loading aura_159.jpg...\n",
      "📤 Loading aura_16.jpg...\n",
      "📤 Loading aura_160.jpg...\n",
      "📤 Loading aura_161.jpg...\n",
      "📤 Loading aura_162.jpg...\n",
      "📤 Loading aura_163.jpg...\n",
      "✅ Completed batch 8\n",
      "📤 Loading minere_157.jpg...\n",
      "📤 Loading minere_158.jpg...\n",
      "📤 Loading minere_159.jpg...\n",
      "📤 Loading minere_16.jpg...\n",
      "📤 Loading minere_160.jpg...\n",
      "📤 Loading minere_161.jpg...\n",
      "📤 Loading minere_162.jpg...\n",
      "📤 Loading minere_163.jpg...\n",
      "✅ Completed batch 9\n",
      "📤 Loading montfleur_157.jpg...\n",
      "📤 Loading montfleur_158.jpg...\n",
      "📤 Loading montfleur_159.jpg...\n",
      "📤 Loading montfleur_16.jpg...\n",
      "📤 Loading montfleur_160.jpg...\n",
      "📤 Loading montfleur_161.jpg...\n",
      "📤 Loading montfleur_162.jpg...\n",
      "📤 Loading montfleur_163.jpg...\n",
      "📤 Loading aura_164.jpg...\n",
      "✅ Completed batch 9\n",
      "📤 Loading aura_165.jpg...\n",
      "📤 Loading aura_166.jpg...\n",
      "📤 Loading aura_167.jpg...\n",
      "📤 Loading aura_168.jpg...\n",
      "📤 Loading aura_169.jpg...\n",
      "📤 Loading aura_17.jpg...\n",
      "📤 Loading aura_170.jpg...\n",
      "📤 Loading minere_164.jpg...\n",
      "📤 Loading minere_165.jpg...\n",
      "✅ Completed batch 9\n",
      "📤 Loading minere_166.jpg...\n",
      "📤 Loading minere_167.jpg...\n",
      "📤 Loading minere_168.jpg...\n",
      "📤 Loading minere_169.jpg...\n",
      "📤 Loading minere_17.jpg...\n",
      "📤 Loading minere_170.jpg...\n",
      "📤 Loading montfleur_164.jpg...\n",
      "✅ Completed batch 10\n",
      "📤 Loading montfleur_165.jpg...\n",
      "📤 Loading montfleur_166.jpg...\n",
      "📤 Loading montfleur_167.jpg...\n",
      "📤 Loading montfleur_168.jpg...\n",
      "📤 Loading montfleur_169.jpg...\n",
      "📤 Loading montfleur_17.jpg...\n",
      "📤 Loading montfleur_170.jpg...\n",
      "✅ Completed batch 10\n",
      "📤 Loading aura_171.jpg...\n",
      "📤 Loading aura_172.jpg...\n",
      "📤 Loading aura_173.jpg...\n",
      "📤 Loading aura_174.jpg...\n",
      "📤 Loading aura_175.jpg...\n",
      "📤 Loading aura_176.jpg...\n",
      "📤 Loading aura_177.jpg...\n",
      "📤 Loading aura_178.jpg...\n",
      "📤 Loading minere_171.jpg...\n",
      "📤 Loading minere_172.jpg...\n",
      "✅ Completed batch 10\n",
      "📤 Loading minere_173.jpg...\n",
      "📤 Loading minere_174.jpg...\n",
      "📤 Loading minere_175.jpg...\n",
      "📤 Loading minere_176.jpg...\n",
      "📤 Loading minere_177.jpg...\n",
      "📤 Loading minere_178.jpg...\n",
      "📤 Loading montfleur_171.jpg...\n",
      "📤 Loading montfleur_172.jpg...\n",
      "✅ Completed batch 11\n",
      "📤 Loading montfleur_173.jpg...\n",
      "📤 Loading montfleur_174.jpg...\n",
      "📤 Loading montfleur_175.jpg...\n",
      "📤 Loading montfleur_176.jpg...\n",
      "📤 Loading montfleur_177.jpg...\n",
      "📤 Loading montfleur_178.jpg...\n",
      "📤 Loading aura_179.jpg...\n",
      "📤 Loading aura_18.jpg...\n",
      "✅ Completed batch 11\n",
      "📤 Loading aura_180.jpg...\n",
      "📤 Loading aura_181.jpg...\n",
      "📤 Loading aura_182.jpg...\n",
      "📤 Loading aura_183.jpg...\n",
      "📤 Loading aura_184.jpg...\n",
      "📤 Loading aura_185.jpg...\n",
      "📤 Loading minere_179.jpg...\n",
      "📤 Loading minere_18.jpg...\n",
      "✅ Completed batch 11\n",
      "📤 Loading minere_180.jpg...\n",
      "📤 Loading minere_181.jpg...\n",
      "📤 Loading minere_182.jpg...\n",
      "📤 Loading minere_183.jpg...\n",
      "📤 Loading minere_184.jpg...\n",
      "📤 Loading minere_185.jpg...\n",
      "✅ Completed batch 12\n",
      "📤 Loading montfleur_179.jpg...\n",
      "📤 Loading montfleur_18.jpg...\n",
      "📤 Loading montfleur_180.jpg...\n",
      "📤 Loading montfleur_181.jpg...\n",
      "📤 Loading montfleur_182.jpg...\n",
      "📤 Loading montfleur_183.jpg...\n",
      "📤 Loading montfleur_184.jpg...\n",
      "📤 Loading montfleur_185.jpg...\n",
      "✅ Completed batch 12\n",
      "📤 Loading minere_186.jpg...\n",
      "📤 Loading aura_187.jpg...\n",
      "📤 Loading aura_188.jpg...\n",
      "📤 Loading aura_189.jpg...\n",
      "📤 Loading aura_19.jpg...\n",
      "📤 Loading aura_190.jpg...\n",
      "📤 Loading aura_191.jpg...\n",
      "📤 Loading aura_192.jpg...\n",
      "✅ Completed batch 12\n",
      "📤 Loading minere_187.jpg...\n",
      "📤 Loading minere_188.jpg...\n",
      "📤 Loading minere_189.jpg...\n",
      "📤 Loading minere_19.jpg...\n",
      "📤 Loading minere_190.jpg...\n",
      "📤 Loading minere_191.jpg...\n",
      "📤 Loading minere_192.jpg...\n",
      "📤 Loading aura_186.jpg...\n",
      "📤 Loading montfleur_186.jpg...\n",
      "📤 Loading montfleur_187.jpg...\n",
      "📤 Loading montfleur_188.jpg...\n",
      "📤 Loading montfleur_189.jpg...\n",
      "📤 Loading montfleur_19.jpg...\n",
      "📤 Loading montfleur_190.jpg...\n",
      "📤 Loading montfleur_191.jpg...\n",
      "📤 Loading montfleur_192.jpg...\n",
      "✅ Completed batch 13\n",
      "✅ Completed batch 13\n",
      "📤 Loading aura_193.jpg...\n",
      "📤 Loading aura_194.jpg...\n",
      "📤 Loading aura_195.jpg...\n",
      "📤 Loading aura_196.jpg...\n",
      "📤 Loading aura_197.jpg...\n",
      "📤 Loading aura_198.jpg...\n",
      "📤 Loading aura_199.jpg...\n",
      "📤 Loading aura_2.jpg...\n",
      "✅ Completed batch 13\n",
      "📤 Loading minere_193.jpg...\n",
      "📤 Loading minere_194.jpg...\n",
      "📤 Loading minere_195.jpg...\n",
      "📤 Loading minere_196.jpg...\n",
      "📤 Loading minere_197.jpg...\n",
      "📤 Loading minere_198.jpg...\n",
      "📤 Loading minere_199.jpg...\n",
      "📤 Loading minere_2.jpg...\n",
      "📤 Loading montfleur_193.jpg...\n",
      "📤 Loading montfleur_194.jpg...\n",
      "✅ Completed batch 14\n",
      "📤 Loading montfleur_195.jpg...\n",
      "📤 Loading montfleur_196.jpg...\n",
      "📤 Loading montfleur_197.jpg...\n",
      "📤 Loading montfleur_198.jpg...\n",
      "📤 Loading montfleur_199.jpg...\n",
      "📤 Loading montfleur_2.jpg...\n",
      "📤 Loading aura_20.jpg...\n",
      "📤 Loading aura_200.jpg...\n",
      "📤 Loading aura_201.jpg...\n",
      "📤 Loading aura_202.jpg...\n",
      "✅ Completed batch 14\n",
      "📤 Loading aura_203.jpg...\n",
      "📤 Loading aura_204.jpg...\n",
      "📤 Loading aura_205.jpg...\n",
      "📤 Loading aura_206.jpg...\n",
      "📤 Loading minere_20.jpg...\n",
      "📤 Loading minere_200.jpg...\n",
      "📤 Loading minere_201.jpg...\n",
      "✅ Completed batch 14\n",
      "📤 Loading minere_202.jpg...\n",
      "📤 Loading minere_203.jpg...\n",
      "📤 Loading minere_204.jpg...\n",
      "📤 Loading minere_205.jpg...\n",
      "📤 Loading minere_206.jpg...\n",
      "📤 Loading montfleur_20.jpg...\n",
      "📤 Loading montfleur_200.jpg...\n",
      "✅ Completed batch 15\n",
      "📤 Loading montfleur_201.jpg...\n",
      "📤 Loading montfleur_202.jpg...\n",
      "📤 Loading montfleur_203.jpg...\n",
      "📤 Loading montfleur_204.jpg...\n",
      "📤 Loading montfleur_205.jpg...\n",
      "📤 Loading montfleur_206.jpg...\n",
      "✅ Completed batch 15\n",
      "📤 Loading aura_207.jpg...\n",
      "📤 Loading aura_208.jpg...\n",
      "📤 Loading aura_209.jpg...\n",
      "📤 Loading aura_21.jpg...\n",
      "📤 Loading aura_210.jpg...\n",
      "📤 Loading aura_211.jpg...\n",
      "📤 Loading aura_212.jpg...\n",
      "📤 Loading aura_213.jpg...\n",
      "✅ Completed batch 15\n",
      "📤 Loading minere_207.jpg...\n",
      "📤 Loading minere_208.jpg...\n",
      "📤 Loading minere_209.jpg...\n",
      "📤 Loading minere_21.jpg...\n",
      "📤 Loading minere_210.jpg...\n",
      "📤 Loading minere_211.jpg...\n",
      "📤 Loading minere_212.jpg...\n",
      "📤 Loading minere_213.jpg...\n",
      "✅ Completed batch 16\n",
      "📤 Loading montfleur_207.jpg...\n",
      "📤 Loading montfleur_208.jpg...\n",
      "📤 Loading montfleur_209.jpg...\n",
      "📤 Loading montfleur_21.jpg...\n",
      "📤 Loading montfleur_210.jpg...\n",
      "📤 Loading montfleur_211.jpg...\n",
      "📤 Loading montfleur_212.jpg...\n",
      "📤 Loading montfleur_213.jpg...\n",
      "✅ Completed batch 16\n",
      "📤 Loading aura_214.jpg...\n",
      "📤 Loading aura_215.jpg...\n",
      "📤 Loading aura_216.jpg...\n",
      "📤 Loading aura_217.jpg...\n",
      "📤 Loading aura_218.jpg...\n",
      "📤 Loading aura_219.jpg...\n",
      "📤 Loading aura_22.jpg...\n",
      "📤 Loading aura_220.jpg...\n",
      "✅ Completed batch 16\n",
      "📤 Loading minere_214.jpg...\n",
      "📤 Loading minere_215.jpg...\n",
      "📤 Loading minere_216.jpg...\n",
      "📤 Loading minere_217.jpg...\n",
      "📤 Loading minere_218.jpg...\n",
      "📤 Loading minere_219.jpg...\n",
      "📤 Loading minere_22.jpg...\n",
      "📤 Loading minere_220.jpg...\n",
      "✅ Completed batch 17\n",
      "📤 Loading montfleur_214.jpg...\n",
      "📤 Loading montfleur_215.jpg...\n",
      "📤 Loading montfleur_216.jpg...\n",
      "📤 Loading montfleur_217.jpg...\n",
      "📤 Loading montfleur_218.jpg...\n",
      "📤 Loading montfleur_219.jpg...\n",
      "📤 Loading montfleur_22.jpg...\n",
      "📤 Loading montfleur_220.jpg...\n",
      "📤 Loading aura_221.jpg...\n",
      "✅ Completed batch 17\n",
      "📤 Loading aura_222.jpg...\n",
      "📤 Loading aura_223.jpg...\n",
      "📤 Loading aura_224.jpg...\n",
      "📤 Loading aura_225.jpg...\n",
      "📤 Loading aura_226.jpg...\n",
      "📤 Loading aura_227.jpg...\n",
      "📤 Loading aura_228.jpg...\n",
      "📤 Loading minere_221.jpg...\n",
      "📤 Loading minere_222.jpg...\n",
      "✅ Completed batch 17\n",
      "📤 Loading minere_223.jpg...\n",
      "📤 Loading minere_224.jpg...\n",
      "📤 Loading minere_225.jpg...\n",
      "📤 Loading minere_226.jpg...\n",
      "📤 Loading minere_227.jpg...\n",
      "📤 Loading minere_228.jpg...\n",
      "📤 Loading montfleur_221.jpg...\n",
      "📤 Loading montfleur_222.jpg...\n",
      "📤 Loading montfleur_223.jpg...\n",
      "📤 Loading montfleur_224.jpg...\n",
      "✅ Completed batch 18\n",
      "📤 Loading montfleur_225.jpg...\n",
      "📤 Loading montfleur_226.jpg...\n",
      "📤 Loading montfleur_227.jpg...\n",
      "📤 Loading montfleur_228.jpg...\n",
      "📤 Loading aura_229.jpg...\n",
      "✅ Completed batch 18\n",
      "📤 Loading aura_23.jpg...\n",
      "📤 Loading aura_230.jpg...\n",
      "📤 Loading aura_231.jpg...\n",
      "📤 Loading aura_232.jpg...\n",
      "📤 Loading aura_233.jpg...\n",
      "📤 Loading aura_234.jpg...\n",
      "📤 Loading aura_235.jpg...\n",
      "📤 Loading minere_229.jpg...\n",
      "📤 Loading minere_23.jpg...\n",
      "✅ Completed batch 18\n",
      "📤 Loading minere_230.jpg...\n",
      "📤 Loading minere_231.jpg...\n",
      "📤 Loading minere_232.jpg...\n",
      "📤 Loading minere_233.jpg...\n",
      "📤 Loading minere_234.jpg...\n",
      "📤 Loading minere_235.jpg...\n",
      "📤 Loading montfleur_229.jpg...\n",
      "📤 Loading montfleur_23.jpg...\n",
      "✅ Completed batch 19\n",
      "📤 Loading montfleur_230.jpg...\n",
      "📤 Loading montfleur_231.jpg...\n",
      "📤 Loading montfleur_232.jpg...\n",
      "📤 Loading montfleur_233.jpg...\n",
      "📤 Loading montfleur_234.jpg...\n",
      "📤 Loading montfleur_235.jpg...\n",
      "✅ Completed batch 19\n",
      "📤 Loading aura_236.jpg...\n",
      "📤 Loading aura_237.jpg...\n",
      "📤 Loading aura_238.jpg...\n",
      "📤 Loading aura_239.jpg...\n",
      "📤 Loading aura_24.jpg...\n",
      "📤 Loading aura_240.jpg...\n",
      "📤 Loading aura_241.jpg...\n",
      "📤 Loading aura_242.jpg...\n",
      "📤 Loading minere_236.jpg...\n",
      "📤 Loading minere_237.jpg...\n",
      "📤 Loading minere_238.jpg...\n",
      "✅ Completed batch 19\n",
      "📤 Loading minere_239.jpg...\n",
      "📤 Loading minere_24.jpg...\n",
      "📤 Loading minere_240.jpg...\n",
      "📤 Loading minere_241.jpg...\n",
      "📤 Loading minere_242.jpg...\n",
      "✅ Completed batch 20\n",
      "📤 Loading montfleur_236.jpg...\n",
      "📤 Loading montfleur_237.jpg...\n",
      "📤 Loading montfleur_238.jpg...\n",
      "📤 Loading montfleur_239.jpg...\n",
      "📤 Loading montfleur_24.jpg...\n",
      "📤 Loading montfleur_240.jpg...\n",
      "📤 Loading montfleur_241.jpg...\n",
      "📤 Loading montfleur_242.jpg...\n",
      "✅ Completed batch 20\n",
      "📤 Loading aura_243.jpg...\n",
      "📤 Loading aura_244.jpg...\n",
      "📤 Loading aura_245.jpg...\n",
      "📤 Loading aura_246.jpg...\n",
      "📤 Loading aura_247.jpg...\n",
      "📤 Loading aura_248.jpg...\n",
      "📤 Loading aura_249.jpg...\n",
      "📤 Loading aura_25.jpg...\n",
      "✅ Completed batch 20\n",
      "📤 Loading minere_243.jpg...\n",
      "📤 Loading minere_244.jpg...\n",
      "📤 Loading minere_245.jpg...\n",
      "📤 Loading minere_246.jpg...\n",
      "📤 Loading minere_247.jpg...\n",
      "📤 Loading minere_248.jpg...\n",
      "📤 Loading minere_249.jpg...\n",
      "📤 Loading minere_25.jpg...\n",
      "📤 Loading montfleur_243.jpg...\n",
      "✅ Completed batch 21\n",
      "📤 Loading montfleur_244.jpg...\n",
      "📤 Loading montfleur_245.jpg...\n",
      "📤 Loading montfleur_246.jpg...\n",
      "📤 Loading montfleur_247.jpg...\n",
      "📤 Loading montfleur_248.jpg...\n",
      "📤 Loading montfleur_249.jpg...\n",
      "📤 Loading montfleur_25.jpg...\n",
      "📤 Loading aura_250.jpg...\n",
      "✅ Completed batch 21\n",
      "📤 Loading aura_251.jpg...\n",
      "📤 Loading aura_252.jpg...\n",
      "📤 Loading aura_253.jpg...\n",
      "📤 Loading aura_254.jpg...\n",
      "📤 Loading aura_255.jpg...\n",
      "📤 Loading aura_256.jpg...\n",
      "📤 Loading aura_257.jpg...\n",
      "📤 Loading minere_250.jpg...\n",
      "✅ Completed batch 21\n",
      "📤 Loading minere_251.jpg...\n",
      "📤 Loading minere_252.jpg...\n",
      "📤 Loading minere_253.jpg...\n",
      "📤 Loading minere_254.jpg...\n",
      "📤 Loading minere_255.jpg...\n",
      "📤 Loading minere_256.jpg...\n",
      "📤 Loading minere_257.jpg...\n",
      "✅ Completed batch 22\n",
      "📤 Loading montfleur_250.jpg...\n",
      "📤 Loading montfleur_251.jpg...\n",
      "📤 Loading montfleur_252.jpg...\n",
      "📤 Loading montfleur_253.jpg...\n",
      "📤 Loading montfleur_254.jpg...\n",
      "📤 Loading montfleur_255.jpg...\n",
      "📤 Loading montfleur_256.jpg...\n",
      "📤 Loading montfleur_257.jpg...\n",
      "📤 Loading aura_258.jpg...\n",
      "✅ Completed batch 22\n",
      "📤 Loading aura_259.jpg...\n",
      "📤 Loading minere_258.jpg...\n",
      "📤 Loading aura_260.jpg...\n",
      "📤 Loading aura_261.jpg...\n",
      "📤 Loading aura_262.jpg...\n",
      "📤 Loading aura_263.jpg...\n",
      "📤 Loading aura_264.jpg...\n",
      "📤 Loading minere_259.jpg...\n",
      "✅ Completed batch 22\n",
      "📤 Loading minere_26.jpg...\n",
      "📤 Loading minere_260.jpg...\n",
      "📤 Loading minere_261.jpg...\n",
      "📤 Loading minere_262.jpg...\n",
      "📤 Loading minere_263.jpg...\n",
      "📤 Loading minere_264.jpg...\n",
      "📤 Loading aura_26.jpg...\n",
      "📤 Loading montfleur_258.jpg...\n",
      "📤 Loading montfleur_259.jpg...\n",
      "📤 Loading montfleur_26.jpg...\n",
      "📤 Loading montfleur_260.jpg...\n",
      "📤 Loading montfleur_261.jpg...\n",
      "📤 Loading montfleur_262.jpg...\n",
      "📤 Loading montfleur_263.jpg...\n",
      "📤 Loading montfleur_264.jpg...\n",
      "✅ Completed batch 23\n",
      "✅ Completed batch 23\n",
      "📤 Loading minere_265.jpg...\n",
      "📤 Loading minere_266.jpg...\n",
      "📤 Loading minere_267.jpg...\n",
      "📤 Loading minere_268.jpg...\n",
      "📤 Loading minere_269.jpg...\n",
      "📤 Loading minere_27.jpg...\n",
      "📤 Loading minere_270.jpg...\n",
      "📤 Loading minere_271.jpg...\n",
      "✅ Completed batch 23\n",
      "📤 Loading aura_265.jpg...\n",
      "📤 Loading aura_266.jpg...\n",
      "📤 Loading aura_267.jpg...\n",
      "📤 Loading aura_268.jpg...\n",
      "📤 Loading aura_269.jpg...\n",
      "📤 Loading aura_27.jpg...\n",
      "📤 Loading aura_270.jpg...\n",
      "📤 Loading aura_271.jpg...\n",
      "📤 Loading montfleur_265.jpg...\n",
      "✅ Completed batch 24\n",
      "📤 Loading montfleur_266.jpg...\n",
      "📤 Loading montfleur_267.jpg...\n",
      "📤 Loading montfleur_268.jpg...\n",
      "📤 Loading montfleur_269.jpg...\n",
      "📤 Loading montfleur_27.jpg...\n",
      "📤 Loading montfleur_270.jpg...\n",
      "📤 Loading montfleur_271.jpg...\n",
      "📤 Loading minere_272.jpg...\n",
      "✅ Completed batch 24\n",
      "📤 Loading minere_273.jpg...\n",
      "📤 Loading minere_274.jpg...\n",
      "📤 Loading minere_275.jpg...\n",
      "📤 Loading minere_276.jpg...\n",
      "📤 Loading minere_277.jpg...\n",
      "📤 Loading minere_278.jpg...\n",
      "📤 Loading minere_279.jpg...\n",
      "📤 Loading aura_272.jpg...\n",
      "📤 Loading aura_273.jpg...\n",
      "✅ Completed batch 24\n",
      "📤 Loading aura_274.jpg...\n",
      "📤 Loading aura_275.jpg...\n",
      "📤 Loading aura_276.jpg...\n",
      "📤 Loading aura_277.jpg...\n",
      "📤 Loading aura_278.jpg...\n",
      "📤 Loading aura_279.jpg...\n",
      "✅ Completed batch 25\n",
      "📤 Loading montfleur_272.jpg...\n",
      "📤 Loading montfleur_273.jpg...\n",
      "📤 Loading montfleur_274.jpg...\n",
      "📤 Loading montfleur_275.jpg...\n",
      "📤 Loading montfleur_276.jpg...\n",
      "📤 Loading montfleur_277.jpg...\n",
      "📤 Loading montfleur_278.jpg...\n",
      "📤 Loading montfleur_279.jpg...\n",
      "✅ Completed batch 25\n",
      "📤 Loading minere_28.jpg...\n",
      "📤 Loading minere_280.jpg...\n",
      "📤 Loading minere_281.jpg...\n",
      "📤 Loading minere_282.jpg...\n",
      "📤 Loading minere_283.jpg...\n",
      "📤 Loading minere_284.jpg...\n",
      "📤 Loading minere_285.jpg...\n",
      "📤 Loading minere_286.jpg...\n",
      "📤 Loading aura_28.jpg...\n",
      "📤 Loading aura_280.jpg...\n",
      "📤 Loading aura_281.jpg...\n",
      "✅ Completed batch 25\n",
      "📤 Loading aura_282.jpg...\n",
      "📤 Loading montfleur_28.jpg...\n",
      "📤 Loading aura_284.jpg...\n",
      "📤 Loading aura_285.jpg...\n",
      "📤 Loading aura_286.jpg...\n",
      "✅ Completed batch 26\n",
      "📤 Loading montfleur_280.jpg...\n",
      "📤 Loading montfleur_281.jpg...\n",
      "📤 Loading montfleur_282.jpg...\n",
      "📤 Loading montfleur_283.jpg...\n",
      "📤 Loading montfleur_284.jpg...\n",
      "📤 Loading montfleur_285.jpg...\n",
      "📤 Loading montfleur_286.jpg...\n",
      "📤 Loading aura_283.jpg...\n",
      "📤 Loading minere_287.jpg...\n",
      "📤 Loading minere_288.jpg...\n",
      "📤 Loading minere_289.jpg...\n",
      "📤 Loading minere_29.jpg...\n",
      "📤 Loading minere_290.jpg...\n",
      "📤 Loading minere_291.jpg...\n",
      "📤 Loading minere_292.jpg...\n",
      "✅ Completed batch 26\n",
      "📤 Loading minere_293.jpg...\n",
      "✅ Completed batch 26\n",
      "📤 Loading aura_287.jpg...\n",
      "📤 Loading aura_288.jpg...\n",
      "📤 Loading aura_289.jpg...\n",
      "📤 Loading aura_29.jpg...\n",
      "📤 Loading aura_290.jpg...\n",
      "📤 Loading aura_291.jpg...\n",
      "📤 Loading aura_292.jpg...\n",
      "📤 Loading aura_293.jpg...\n",
      "✅ Completed batch 27\n",
      "📤 Loading montfleur_287.jpg...\n",
      "📤 Loading montfleur_288.jpg...\n",
      "📤 Loading montfleur_289.jpg...\n",
      "📤 Loading montfleur_29.jpg...\n",
      "📤 Loading montfleur_290.jpg...\n",
      "📤 Loading montfleur_291.jpg...\n",
      "📤 Loading montfleur_292.jpg...\n",
      "📤 Loading montfleur_293.jpg...\n",
      "📤 Loading minere_294.jpg...\n",
      "✅ Completed batch 27\n",
      "📤 Loading minere_295.jpg...\n",
      "📤 Loading minere_296.jpg...\n",
      "📤 Loading minere_297.jpg...\n",
      "📤 Loading minere_298.jpg...\n",
      "📤 Loading minere_299.jpg...\n",
      "📤 Loading minere_3.jpg...\n",
      "📤 Loading minere_30.jpg...\n",
      "📤 Loading aura_294.jpg...\n",
      "✅ Completed batch 27\n",
      "📤 Loading aura_295.jpg...\n",
      "📤 Loading aura_296.jpg...\n",
      "📤 Loading aura_297.jpg...\n",
      "📤 Loading aura_298.jpg...\n",
      "📤 Loading aura_299.jpg...\n",
      "📤 Loading aura_3.jpg...\n",
      "📤 Loading aura_30.jpg...\n",
      "📤 Loading montfleur_294.jpg...\n",
      "✅ Completed batch 28\n",
      "📤 Loading montfleur_295.jpg...\n",
      "📤 Loading montfleur_296.jpg...\n",
      "📤 Loading montfleur_297.jpg...\n",
      "📤 Loading montfleur_298.jpg...\n",
      "📤 Loading montfleur_299.jpg...\n",
      "📤 Loading montfleur_3.jpg...\n",
      "📤 Loading montfleur_30.jpg...\n",
      "📤 Loading minere_300.jpg...\n",
      "📤 Loading minere_301.jpg...\n",
      "✅ Completed batch 28\n",
      "📤 Loading minere_302.jpg...\n",
      "📤 Loading minere_303.jpg...\n",
      "📤 Loading minere_304.jpg...\n",
      "📤 Loading minere_305.jpg...\n",
      "📤 Loading minere_306.jpg...\n",
      "📤 Loading minere_307.jpg...\n",
      "📤 Loading aura_300.jpg...\n",
      "📤 Loading aura_301.jpg...\n",
      "✅ Completed batch 28\n",
      "📤 Loading aura_302.jpg...\n",
      "📤 Loading aura_303.jpg...\n",
      "📤 Loading aura_304.jpg...\n",
      "📤 Loading aura_305.jpg...\n",
      "📤 Loading aura_306.jpg...\n",
      "📤 Loading aura_307.jpg...\n",
      "✅ Completed batch 29\n",
      "📤 Loading montfleur_300.jpg...\n",
      "📤 Loading montfleur_301.jpg...\n",
      "📤 Loading montfleur_302.jpg...\n",
      "📤 Loading montfleur_303.jpg...\n",
      "📤 Loading montfleur_304.jpg...\n",
      "📤 Loading montfleur_305.jpg...\n",
      "📤 Loading montfleur_306.jpg...\n",
      "📤 Loading montfleur_307.jpg...\n",
      "✅ Completed batch 29\n",
      "📤 Loading minere_308.jpg...\n",
      "📤 Loading minere_309.jpg...\n",
      "📤 Loading minere_31.jpg...\n",
      "📤 Loading minere_310.jpg...\n",
      "📤 Loading minere_311.jpg...\n",
      "📤 Loading minere_312.jpg...\n",
      "📤 Loading minere_313.jpg...\n",
      "📤 Loading minere_314.jpg...\n",
      "✅ Completed batch 29\n",
      "📤 Loading aura_308.jpg...\n",
      "📤 Loading aura_309.jpg...\n",
      "📤 Loading aura_31.jpg...\n",
      "📤 Loading aura_310.jpg...\n",
      "📤 Loading aura_311.jpg...\n",
      "📤 Loading aura_312.jpg...\n",
      "📤 Loading aura_313.jpg...\n",
      "📤 Loading aura_314.jpg...\n",
      "📤 Loading montfleur_308.jpg...\n",
      "📤 Loading montfleur_309.jpg...\n",
      "✅ Completed batch 30\n",
      "📤 Loading montfleur_31.jpg...\n",
      "📤 Loading montfleur_310.jpg...\n",
      "📤 Loading montfleur_311.jpg...\n",
      "📤 Loading montfleur_312.jpg...\n",
      "📤 Loading montfleur_313.jpg...\n",
      "📤 Loading montfleur_314.jpg...\n",
      "✅ Completed batch 30\n",
      "📤 Loading minere_315.jpg...\n",
      "📤 Loading minere_316.jpg...\n",
      "📤 Loading minere_317.jpg...\n",
      "📤 Loading minere_318.jpg...\n",
      "📤 Loading minere_319.jpg...\n",
      "📤 Loading minere_32.jpg...\n",
      "📤 Loading minere_320.jpg...\n",
      "📤 Loading minere_321.jpg...\n",
      "📤 Loading aura_315.jpg...\n",
      "📤 Loading aura_316.jpg...\n",
      "📤 Loading aura_317.jpg...\n",
      "✅ Completed batch 30\n",
      "📤 Loading aura_318.jpg...\n",
      "📤 Loading aura_319.jpg...\n",
      "📤 Loading aura_32.jpg...\n",
      "📤 Loading aura_320.jpg...\n",
      "📤 Loading aura_321.jpg...\n",
      "📤 Loading montfleur_315.jpg...\n",
      "📤 Loading montfleur_316.jpg...\n",
      "✅ Completed batch 31\n",
      "📤 Loading montfleur_317.jpg...\n",
      "📤 Loading montfleur_318.jpg...\n",
      "📤 Loading montfleur_319.jpg...\n",
      "📤 Loading montfleur_32.jpg...\n",
      "📤 Loading montfleur_320.jpg...\n",
      "📤 Loading montfleur_321.jpg...\n",
      "📤 Loading minere_322.jpg...\n",
      "📤 Loading minere_323.jpg...\n",
      "📤 Loading minere_324.jpg...\n",
      "✅ Completed batch 31\n",
      "📤 Loading minere_325.jpg...\n",
      "📤 Loading minere_326.jpg...\n",
      "📤 Loading minere_327.jpg...\n",
      "📤 Loading minere_328.jpg...\n",
      "📤 Loading minere_329.jpg...\n",
      "📤 Loading aura_322.jpg...\n",
      "📤 Loading aura_323.jpg...\n",
      "📤 Loading aura_324.jpg...\n",
      "📤 Loading aura_325.jpg...\n",
      "✅ Completed batch 31\n",
      "📤 Loading aura_326.jpg...\n",
      "📤 Loading aura_327.jpg...\n",
      "📤 Loading aura_328.jpg...\n",
      "📤 Loading aura_329.jpg...\n",
      "📤 Loading montfleur_322.jpg...\n",
      "✅ Completed batch 32\n",
      "📤 Loading montfleur_323.jpg...\n",
      "📤 Loading montfleur_324.jpg...\n",
      "📤 Loading montfleur_325.jpg...\n",
      "📤 Loading montfleur_326.jpg...\n",
      "📤 Loading montfleur_327.jpg...\n",
      "📤 Loading montfleur_328.jpg...\n",
      "📤 Loading montfleur_329.jpg...\n",
      "📤 Loading minere_33.jpg...\n",
      "✅ Completed batch 32\n",
      "📤 Loading minere_330.jpg...\n",
      "📤 Loading minere_34.jpg...\n",
      "📤 Loading minere_35.jpg...\n",
      "📤 Loading minere_36.jpg...\n",
      "📤 Loading minere_37.jpg...\n",
      "📤 Loading minere_38.jpg...\n",
      "📤 Loading minere_39.jpg...\n",
      "📤 Loading aura_33.jpg...\n",
      "✅ Completed batch 32\n",
      "📤 Loading aura_330.jpg...\n",
      "📤 Loading aura_34.jpg...\n",
      "📤 Loading aura_35.jpg...\n",
      "📤 Loading aura_36.jpg...\n",
      "📤 Loading aura_37.jpg...\n",
      "📤 Loading aura_38.jpg...\n",
      "📤 Loading aura_39.jpg...\n",
      "📤 Loading montfleur_33.jpg...\n",
      "📤 Loading montfleur_330.jpg...\n",
      "📤 Loading montfleur_34.jpg...\n",
      "✅ Completed batch 33\n",
      "📤 Loading montfleur_35.jpg...\n",
      "📤 Loading montfleur_36.jpg...\n",
      "📤 Loading montfleur_37.jpg...\n",
      "📤 Loading montfleur_38.jpg...\n",
      "📤 Loading montfleur_39.jpg...\n",
      "✅ Completed batch 33\n",
      "📤 Loading minere_4.jpg...\n",
      "📤 Loading minere_40.jpg...\n",
      "📤 Loading minere_41.jpg...\n",
      "📤 Loading minere_42.jpg...\n",
      "📤 Loading minere_43.jpg...\n",
      "📤 Loading minere_44.jpg...\n",
      "📤 Loading minere_45.jpg...\n",
      "📤 Loading minere_46.jpg...\n",
      "✅ Completed batch 33\n",
      "📤 Loading aura_4.jpg...\n",
      "📤 Loading aura_40.jpg...\n",
      "📤 Loading aura_41.jpg...\n",
      "📤 Loading aura_42.jpg...\n",
      "📤 Loading aura_43.jpg...\n",
      "📤 Loading aura_44.jpg...\n",
      "📤 Loading aura_45.jpg...\n",
      "📤 Loading aura_46.jpg...\n",
      "📤 Loading montfleur_4.jpg...\n",
      "✅ Completed batch 34\n",
      "📤 Loading montfleur_40.jpg...\n",
      "📤 Loading montfleur_41.jpg...\n",
      "📤 Loading montfleur_42.jpg...\n",
      "📤 Loading montfleur_43.jpg...\n",
      "📤 Loading montfleur_44.jpg...\n",
      "📤 Loading montfleur_45.jpg...\n",
      "📤 Loading montfleur_46.jpg...\n",
      "✅ Completed batch 34\n",
      "📤 Loading minere_47.jpg...\n",
      "📤 Loading minere_48.jpg...\n",
      "📤 Loading minere_49.jpg...\n",
      "📤 Loading minere_5.jpg...\n",
      "📤 Loading minere_50.jpg...\n",
      "📤 Loading minere_51.jpg...\n",
      "📤 Loading minere_52.jpg...\n",
      "📤 Loading minere_53.jpg...\n",
      "📤 Loading aura_47.jpg...\n",
      "✅ Completed batch 34\n",
      "📤 Loading aura_48.jpg...\n",
      "📤 Loading aura_49.jpg...\n",
      "📤 Loading aura_5.jpg...\n",
      "📤 Loading aura_50.jpg...\n",
      "📤 Loading aura_51.jpg...\n",
      "📤 Loading aura_52.jpg...\n",
      "📤 Loading aura_53.jpg...\n",
      "📤 Loading montfleur_47.jpg...\n",
      "📤 Loading montfleur_48.jpg...\n",
      "✅ Completed batch 35\n",
      "📤 Loading montfleur_49.jpg...\n",
      "📤 Loading montfleur_5.jpg...\n",
      "📤 Loading montfleur_50.jpg...\n",
      "📤 Loading montfleur_51.jpg...\n",
      "📤 Loading montfleur_52.jpg...\n",
      "📤 Loading montfleur_53.jpg...\n",
      "✅ Completed batch 35\n",
      "📤 Loading minere_54.jpg...\n",
      "📤 Loading minere_55.jpg...\n",
      "📤 Loading minere_56.jpg...\n",
      "📤 Loading minere_57.jpg...\n",
      "📤 Loading minere_58.jpg...\n",
      "📤 Loading minere_59.jpg...\n",
      "📤 Loading minere_6.jpg...\n",
      "📤 Loading minere_60.jpg...\n",
      "📤 Loading aura_54.jpg...\n",
      "📤 Loading aura_55.jpg...\n",
      "✅ Completed batch 35\n",
      "📤 Loading aura_56.jpg...\n",
      "📤 Loading aura_57.jpg...\n",
      "📤 Loading aura_58.jpg...\n",
      "📤 Loading aura_59.jpg...\n",
      "📤 Loading aura_6.jpg...\n",
      "📤 Loading aura_60.jpg...\n",
      "✅ Completed batch 36\n",
      "📤 Loading montfleur_54.jpg...\n",
      "📤 Loading montfleur_55.jpg...\n",
      "📤 Loading montfleur_56.jpg...\n",
      "📤 Loading montfleur_57.jpg...\n",
      "📤 Loading montfleur_58.jpg...\n",
      "📤 Loading montfleur_59.jpg...\n",
      "📤 Loading montfleur_6.jpg...\n",
      "📤 Loading montfleur_60.jpg...\n",
      "📤 Loading minere_61.jpg...\n",
      "✅ Completed batch 36\n",
      "📤 Loading minere_62.jpg...\n",
      "📤 Loading minere_63.jpg...\n",
      "📤 Loading minere_64.jpg...\n",
      "📤 Loading minere_65.jpg...\n",
      "📤 Loading minere_66.jpg...\n",
      "📤 Loading minere_67.jpg...\n",
      "📤 Loading minere_68.jpg...\n",
      "✅ Completed batch 36\n",
      "📤 Loading aura_61.jpg...\n",
      "📤 Loading aura_62.jpg...\n",
      "📤 Loading aura_63.jpg...\n",
      "📤 Loading aura_64.jpg...\n",
      "📤 Loading aura_65.jpg...\n",
      "📤 Loading aura_66.jpg...\n",
      "📤 Loading aura_67.jpg...\n",
      "📤 Loading aura_68.jpg...\n",
      "📤 Loading montfleur_61.jpg...\n",
      "✅ Completed batch 37\n",
      "📤 Loading montfleur_62.jpg...\n",
      "📤 Loading montfleur_63.jpg...\n",
      "📤 Loading montfleur_64.jpg...\n",
      "📤 Loading montfleur_65.jpg...\n",
      "📤 Loading montfleur_66.jpg...\n",
      "📤 Loading montfleur_67.jpg...\n",
      "📤 Loading montfleur_68.jpg...\n",
      "📤 Loading minere_69.jpg...\n",
      "✅ Completed batch 37\n",
      "📤 Loading minere_7.jpg...\n",
      "📤 Loading minere_70.jpg...\n",
      "📤 Loading minere_71.jpg...\n",
      "📤 Loading minere_72.jpg...\n",
      "📤 Loading minere_73.jpg...\n",
      "📤 Loading minere_74.jpg...\n",
      "📤 Loading minere_75.jpg...\n",
      "📤 Loading aura_69.jpg...\n",
      "✅ Completed batch 37\n",
      "📤 Loading aura_7.jpg...\n",
      "📤 Loading aura_70.jpg...\n",
      "📤 Loading aura_71.jpg...\n",
      "📤 Loading aura_72.jpg...\n",
      "📤 Loading aura_73.jpg...\n",
      "📤 Loading aura_74.jpg...\n",
      "📤 Loading aura_75.jpg...\n",
      "✅ Completed batch 38\n",
      "📤 Loading minere_76.jpg...\n",
      "📤 Loading minere_77.jpg...\n",
      "📤 Loading montfleur_70.jpg...\n",
      "📤 Loading montfleur_71.jpg...\n",
      "📤 Loading montfleur_72.jpg...\n",
      "📤 Loading montfleur_73.jpg...\n",
      "📤 Loading montfleur_74.jpg...\n",
      "📤 Loading montfleur_75.jpg...\n",
      "✅ Completed batch 38\n",
      "📤 Loading minere_78.jpg...\n",
      "📤 Loading minere_79.jpg...\n",
      "📤 Loading minere_8.jpg...\n",
      "📤 Loading minere_80.jpg...\n",
      "📤 Loading minere_81.jpg...\n",
      "📤 Loading minere_82.jpg...\n",
      "📤 Loading montfleur_69.jpg...\n",
      "📤 Loading montfleur_7.jpg...\n",
      "📤 Loading aura_76.jpg...\n",
      "📤 Loading aura_77.jpg...\n",
      "📤 Loading aura_78.jpg...\n",
      "📤 Loading aura_79.jpg...\n",
      "📤 Loading aura_8.jpg...\n",
      "📤 Loading aura_80.jpg...\n",
      "✅ Completed batch 39\n",
      "📤 Loading aura_81.jpg...\n",
      "📤 Loading aura_82.jpg...\n",
      "📤 Loading minere_83.jpg...\n",
      "📤 Loading minere_84.jpg...\n",
      "✅ Completed batch 38\n",
      "📤 Loading minere_85.jpg...\n",
      "📤 Loading minere_86.jpg...\n",
      "📤 Loading minere_87.jpg...\n",
      "📤 Loading minere_88.jpg...\n",
      "📤 Loading minere_89.jpg...\n",
      "📤 Loading minere_9.jpg...\n",
      "📤 Loading montfleur_76.jpg...\n",
      "📤 Loading montfleur_77.jpg...\n",
      "📤 Loading montfleur_78.jpg...\n",
      "✅ Completed batch 39\n",
      "📤 Loading montfleur_79.jpg...\n",
      "📤 Loading montfleur_8.jpg...\n",
      "📤 Loading montfleur_80.jpg...\n",
      "📤 Loading montfleur_81.jpg...\n",
      "📤 Loading montfleur_82.jpg...\n",
      "📤 Loading aura_83.jpg...\n",
      "✅ Completed batch 40\n",
      "📤 Loading aura_84.jpg...\n",
      "📤 Loading aura_85.jpg...\n",
      "📤 Loading aura_86.jpg...\n",
      "📤 Loading aura_87.jpg...\n",
      "📤 Loading aura_88.jpg...\n",
      "📤 Loading aura_89.jpg...\n",
      "📤 Loading aura_9.jpg...\n",
      "✅ Completed batch 39\n",
      "📤 Loading minere_90.jpg...\n",
      "📤 Loading minere_91.jpg...\n",
      "📤 Loading minere_92.jpg...\n",
      "📤 Loading minere_93.jpg...\n",
      "📤 Loading minere_94.jpg...\n",
      "📤 Loading minere_95.jpg...\n",
      "📤 Loading minere_96.jpg...\n",
      "📤 Loading minere_97.jpg...\n",
      "✅ Completed batch 40\n",
      "📤 Loading montfleur_83.jpg...\n",
      "📤 Loading montfleur_84.jpg...\n",
      "📤 Loading montfleur_85.jpg...\n",
      "📤 Loading montfleur_86.jpg...\n",
      "📤 Loading montfleur_87.jpg...\n",
      "📤 Loading montfleur_88.jpg...\n",
      "📤 Loading montfleur_89.jpg...\n",
      "📤 Loading montfleur_9.jpg...\n",
      "✅ Completed batch 41\n",
      "📤 Loading aura_90.jpg...\n",
      "📤 Loading aura_91.jpg...\n",
      "📤 Loading aura_92.jpg...\n",
      "📤 Loading aura_93.jpg...\n",
      "📤 Loading aura_94.jpg...\n",
      "📤 Loading aura_95.jpg...\n",
      "📤 Loading aura_96.jpg...\n",
      "📤 Loading aura_97.jpg...\n",
      "✅ Completed batch 40\n",
      "📤 Loading minere_98.jpg...\n",
      "📤 Loading minere_99.jpg...\n",
      "📤 Loading montfleur_90.jpg...\n",
      "📤 Loading montfleur_91.jpg...\n",
      "📤 Loading montfleur_92.jpg...\n",
      "📤 Loading montfleur_93.jpg...\n",
      "📤 Loading montfleur_94.jpg...\n",
      "📤 Loading montfleur_95.jpg...\n",
      "✅ Completed batch 41\n",
      "📤 Loading montfleur_96.jpg...\n",
      "📤 Loading montfleur_97.jpg...\n",
      "📤 Loading aura_98.jpg...\n",
      "📤 Loading aura_99.jpg...\n",
      "✅ Completed batch 42\n",
      "✅ Completed batch 42\n",
      "✅ Completed batch 41\n",
      "📤 Loading montfleur_98.jpg...\n",
      "📤 Loading montfleur_99.jpg...\n",
      "✅ Completed batch 42\n",
      "🎯 All done! PC survived! 🎉\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import asyncio\n",
    "import psutil\n",
    "from functools import partial\n",
    "\n",
    "dataset_path = \"dataset\"\n",
    "augmented_path = \"augmented\"\n",
    "class_names = [\"aura\", \"minere\", \"montfleur\"]\n",
    "MAX_WORKERS = min(8, psutil.cpu_count() + 2)\n",
    "MEMORY_SAFE_MODE = True\n",
    "CHUNK_SIZE = 2\n",
    "\n",
    "print(f\"⚙️  Config: Workers={MAX_WORKERS}, Chunk={CHUNK_SIZE}, SafeMode={MEMORY_SAFE_MODE}\")\n",
    "\n",
    "semaphore = asyncio.Semaphore(MAX_WORKERS)\n",
    "\n",
    "async def memory_check():\n",
    "    \"\"\"Non-blocking memory monitor\"\"\"\n",
    "    if MEMORY_SAFE_MODE and psutil.virtual_memory().percent > 75:\n",
    "        print(\"💤 Memory buffer...\")\n",
    "        await asyncio.sleep(2)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def process_image_batch(img_path, num_augments):\n",
    "    \"\"\"Process image and return augmented images (let Python's GC handle cleanup)\"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        augmented = augment_image(image, num_augments=num_augments)\n",
    "        # No need to explicitly delete 'image'\n",
    "        return augmented\n",
    "    finally:\n",
    "        cv2.waitKey(1)  # Release OpenCV hooks\n",
    "\n",
    "async def augment_single_image(filename, image_dir, output_dir, idx_i, num_augments):\n",
    "    async with semaphore:\n",
    "        if await memory_check():\n",
    "            await asyncio.sleep(1)\n",
    "\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        print(f\"📤 Loading {filename}...\")\n",
    "        \n",
    "        # Process with memory limits\n",
    "        augmented_images = await asyncio.to_thread(\n",
    "            partial(process_image_batch, num_augments=num_augments),\n",
    "            img_path\n",
    "        )\n",
    "\n",
    "        # Process in chunks\n",
    "        write_tasks = []\n",
    "        base_name = os.path.splitext(filename)[0].split('_')[0]\n",
    "        \n",
    "        for idx_j, aug in enumerate(augmented_images):\n",
    "            if idx_j % CHUNK_SIZE == 0 and idx_j != 0:\n",
    "                await asyncio.gather(*write_tasks)\n",
    "                write_tasks.clear()\n",
    "                await asyncio.sleep(0.2)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{base_name}_aug_{idx_i}_{idx_j}.jpg\")\n",
    "            aug_np = aug.permute(1, 2, 0).numpy()\n",
    "            aug_bgr = cv2.cvtColor(aug_np, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            write_tasks.append(\n",
    "                asyncio.to_thread(cv2.imwrite, output_path, aug_bgr)\n",
    "            )\n",
    "\n",
    "        # Final flush of remaining tasks\n",
    "        if write_tasks:\n",
    "            await asyncio.gather(*write_tasks)\n",
    "\n",
    "        # Let variables go out of scope naturally\n",
    "        await asyncio.sleep(0.2)\n",
    "\n",
    "async def process_augment_class(class_name):\n",
    "    image_dir = os.path.join(dataset_path, class_name)\n",
    "    output_dir = os.path.join(augmented_path, class_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    filenames = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "    print(f\"🔥 Starting {class_name} ({len(filenames)} images)\")\n",
    "\n",
    "    # Process in smaller batches\n",
    "    BATCH_SIZE = MAX_WORKERS * 1  # Reduced multiplier\n",
    "    for batch_idx in range(0, len(filenames), BATCH_SIZE):\n",
    "        batch = filenames[batch_idx:batch_idx+BATCH_SIZE]\n",
    "        \n",
    "        tasks = [\n",
    "            augment_single_image(filename, image_dir, output_dir, idx_i, 8)\n",
    "            for idx_i, filename in enumerate(batch, start=batch_idx)\n",
    "        ]\n",
    "        \n",
    "        await asyncio.gather(*tasks)\n",
    "        print(f\"✅ Completed batch {batch_idx//BATCH_SIZE + 1}\")\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "async def main():\n",
    "    print(\"🚀 Starting SAFE augmentation...\")\n",
    "    await asyncio.gather(*[process_augment_class(cls) for cls in class_names])\n",
    "    print(\"🎯 All done! PC survived! 🎉\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "\n",
    "def parse_image(image_path, label):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode image\n",
    "    img = tf.image.resize(img, [RESIZE_HEIGHT, RESIZE_WIDTH])\n",
    "    print(f\"Resized image shape: {img.shape}\")\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "def prepare_tf_dataset(data_dir=\"augmented\", original_data_dir=\"original\", batch_size=32, seed=42):\n",
    "    # Process class directories for augmented and original data\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "    print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "    \n",
    "    # Prepare augmented dataset (training)\n",
    "    augmented_image_paths = []\n",
    "    augmented_labels = []\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        image_paths = [os.path.join(class_dir, filename) \n",
    "                       for filename in os.listdir(class_dir) \n",
    "                       if filename.endswith('.jpg')]\n",
    "        augmented_image_paths.extend(image_paths)\n",
    "        augmented_labels.extend([class_idx] * len(image_paths))\n",
    "    \n",
    "    # Prepare original dataset (validation & test)\n",
    "    original_image_paths = []\n",
    "    original_labels = []\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(original_data_dir, class_name)\n",
    "        image_paths = [os.path.join(class_dir, filename) \n",
    "                       for filename in os.listdir(class_dir) \n",
    "                       if filename.endswith('.jpg')]\n",
    "        original_image_paths.extend(image_paths)\n",
    "        original_labels.extend([class_idx] * len(image_paths))\n",
    "    \n",
    "    # Shuffle augmented dataset (training)\n",
    "    combined = list(zip(augmented_image_paths, augmented_labels))\n",
    "    random.Random(seed).shuffle(combined)\n",
    "    augmented_image_paths, augmented_labels = zip(*combined)\n",
    "\n",
    "    # Shuffle original dataset (validation & test)\n",
    "    combined_original = list(zip(original_image_paths, original_labels))\n",
    "    random.Random(seed).shuffle(combined_original)\n",
    "    original_image_paths, original_labels = zip(*combined_original)\n",
    "    \n",
    "    # Use all augmented images for training\n",
    "    train_paths, train_labels = list(augmented_image_paths[:]), list(augmented_labels[:])\n",
    "    \n",
    "    # Fix constant length for validation and test\n",
    "    start_idx = random.randint(0, 990 - 792 - 1)\n",
    "    val_paths, val_labels = list(original_image_paths[start_idx:start_idx + 792]), list(original_labels[start_idx:start_idx + 792])\n",
    "\n",
    "    start_idx = random.randint(0, 990 - 792 - 1)\n",
    "    test_paths, test_labels = list(original_image_paths[start_idx:start_idx + 792]), list(original_labels[start_idx:start_idx + 792])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = train_dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    val_dataset = val_dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    val_dataset = val_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    test_dataset = test_dataset.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=1024, seed=seed)\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    print(f\"Traing dataset: {len(train_paths)} images\")\n",
    "    print(f\"Validation dataset: {len(val_paths)} images\")\n",
    "    print(f\"Test dataset: {len(test_paths)} images\")\n",
    "    print(\"🔥 Datasets ready!\")\n",
    "    return train_dataset, val_dataset, test_dataset, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def print_dataset_examples(dataset, class_names):\n",
    "    for images, labels in dataset.take(1):\n",
    "        print(f\"Image batch shape: {images.shape}\")\n",
    "        \n",
    "        # Flatten the images to 1D arrays and create a DataFrame\n",
    "        flattened_images = [image.numpy().flatten() for image in images]  # Flatten the images\n",
    "        labels_as_strings = [class_names[label.numpy()] for label in labels]  # Convert labels to class names\n",
    "        \n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(flattened_images)\n",
    "        df['label'] = labels_as_strings  # Add class labels to the DataFrame\n",
    "        \n",
    "        # Display the DataFrame\n",
    "        print(\"Dataset Examples (Flattened images and labels):\")\n",
    "        print(df.head())  # Display the first 5 rows of the DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 classes: ['aura', 'minere', 'montfleur']\n",
      "Resized image shape: (192, 192, 3)\n",
      "Resized image shape: (192, 192, 3)\n",
      "Resized image shape: (192, 192, 3)\n",
      "Traing dataset: 7920 images\n",
      "Validation dataset: 792 images\n",
      "Test dataset: 792 images\n",
      "🔥 Datasets ready!\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "SEED = 42\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, class_names = prepare_tf_dataset(\n",
    "    data_dir=\"augmented\",\n",
    "    original_data_dir=\"dataset\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - Label: 1\n",
      "Image 2 - Label: 2\n",
      "Image 3 - Label: 2\n",
      "Image 4 - Label: 2\n",
      "Image 5 - Label: 1\n",
      "Image 6 - Label: 1\n",
      "Image 7 - Label: 1\n",
      "Image 8 - Label: 0\n",
      "Image 1 - Label: 0\n",
      "Image 2 - Label: 0\n",
      "Image 3 - Label: 1\n",
      "Image 4 - Label: 0\n",
      "Image 5 - Label: 1\n",
      "Image 6 - Label: 0\n",
      "Image 7 - Label: 1\n",
      "Image 8 - Label: 2\n",
      "Image 1 - Label: 2\n",
      "Image 2 - Label: 1\n",
      "Image 3 - Label: 2\n",
      "Image 4 - Label: 0\n",
      "Image 5 - Label: 2\n",
      "Image 6 - Label: 2\n",
      "Image 7 - Label: 0\n",
      "Image 8 - Label: 0\n",
      "Image 1 - Label: 0\n",
      "Image 2 - Label: 0\n",
      "Image 3 - Label: 1\n",
      "Image 4 - Label: 0\n",
      "Image 5 - Label: 0\n",
      "Image 6 - Label: 1\n",
      "Image 7 - Label: 0\n",
      "Image 8 - Label: 1\n",
      "Image 1 - Label: 2\n",
      "Image 2 - Label: 1\n",
      "Image 3 - Label: 0\n",
      "Image 4 - Label: 1\n",
      "Image 5 - Label: 1\n",
      "Image 6 - Label: 1\n",
      "Image 7 - Label: 0\n",
      "Image 8 - Label: 0\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dataset.take(5):  # `take(1)` will fetch just one batch\n",
    "    for i in range(len(labels)):\n",
    "        print(f\"Image {i+1} - Label: {labels[i].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (10, 192, 192, 3)\n",
      "Dataset Examples (Flattened images and labels):\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.647059  0.647059  0.647059  0.623529  0.623529  0.623529  0.517647   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.705882  0.705882  0.705882  0.701961  0.701961  0.701961  0.698039   \n",
      "\n",
      "          7         8         9  ...    110583    110584    110585    110586  \\\n",
      "0  0.517647  0.517647  0.403922  ...  0.235294  0.235294  0.235294  0.282353   \n",
      "1  0.000000  0.000000  0.000000  ...  0.427451  0.427451  0.427451  0.490196   \n",
      "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.000000  ...  0.101961  0.101961  0.101961  0.058824   \n",
      "4  0.698039  0.698039  0.701961  ...  0.239216  0.239216  0.239216  0.329412   \n",
      "\n",
      "     110587    110588    110589    110590    110591      label  \n",
      "0  0.282353  0.282353  0.286275  0.286275  0.286275  montfleur  \n",
      "1  0.490196  0.490196  0.611765  0.611765  0.611765  montfleur  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000       aura  \n",
      "3  0.058824  0.058824  0.172549  0.172549  0.172549       aura  \n",
      "4  0.329412  0.329412  0.317647  0.317647  0.317647  montfleur  \n",
      "\n",
      "[5 rows x 110593 columns]\n",
      "Image batch shape: (10, 192, 192, 3)\n",
      "Dataset Examples (Flattened images and labels):\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.839216  0.819608  0.741176  0.839706  0.820098  0.741667  0.843137   \n",
      "1  0.835294  0.815686  0.737255  0.842647  0.815196  0.740686  0.843137   \n",
      "2  0.807843  0.784314  0.721569  0.807843  0.784314  0.721569  0.807843   \n",
      "3  0.534314  0.522549  0.463725  0.552941  0.529412  0.474510  0.591667   \n",
      "4  0.818137  0.794608  0.731863  0.816176  0.792647  0.729902  0.819608   \n",
      "\n",
      "          7         8         9  ...    110583    110584    110585    110586  \\\n",
      "0  0.823529  0.745098  0.843137  ...  0.431863  0.431863  0.431863  0.288725   \n",
      "1  0.815686  0.741176  0.847059  ...  0.267157  0.271078  0.251471  0.269118   \n",
      "2  0.784314  0.721569  0.807843  ...  0.450490  0.485784  0.481863  0.415196   \n",
      "3  0.568137  0.513235  0.564706  ...  0.552941  0.529412  0.474510  0.534804   \n",
      "4  0.796078  0.733333  0.821078  ...  0.323039  0.307353  0.311274  0.273529   \n",
      "\n",
      "     110587    110588    110589    110590    110591      label  \n",
      "0  0.274020  0.277941  0.449020  0.441176  0.445098  montfleur  \n",
      "1  0.273039  0.253431  0.280882  0.284804  0.265196     minere  \n",
      "2  0.430882  0.426961  0.424510  0.440196  0.436274       aura  \n",
      "3  0.511275  0.448529  0.524510  0.500980  0.438235  montfleur  \n",
      "4  0.257843  0.261765  0.362255  0.346569  0.350490     minere  \n",
      "\n",
      "[5 rows x 110593 columns]\n"
     ]
    }
   ],
   "source": [
    "print_dataset_examples(train_dataset, class_names)\n",
    "print_dataset_examples(test_dataset, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['aura', 'minere', 'montfleur']\n",
      "Shape of train images: (10, 192, 192, 3)\n",
      "Shape of train labels: (10,)\n",
      "Images type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Labels type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Images dtype: <dtype: 'float32'>\n",
      "Labels dtype: <dtype: 'int32'>\n",
      "Shape of test images: (10, 192, 192, 3)\n",
      "Shape of test labels: (10,)\n",
      "Images type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Labels type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Images dtype: <dtype: 'float32'>\n",
      "Labels dtype: <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Shape of train images: {images.shape}\")\n",
    "    print(f\"Shape of train labels: {labels.shape}\")\n",
    "    print(f\"Images type: {type(images)}\")\n",
    "    print(f\"Labels type: {type(labels)}\")\n",
    "    print(f\"Images dtype: {images.dtype}\")\n",
    "    print(f\"Labels dtype: {labels.dtype}\")\n",
    "\n",
    "for images, labels in test_dataset.take(1):\n",
    "    print(f\"Shape of test images: {images.shape}\")\n",
    "    print(f\"Shape of test labels: {labels.shape}\")\n",
    "    print(f\"Images type: {type(images)}\")\n",
    "    print(f\"Labels type: {type(labels)}\")\n",
    "    print(f\"Images dtype: {images.dtype}\")\n",
    "    print(f\"Labels dtype: {labels.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow is using a GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Force_Grayscale (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">95</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25600</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">76,803</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Force_Grayscale (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m192\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │            \u001b[38;5;34m12\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m190\u001b[0m, \u001b[38;5;34m190\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m95\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25600\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │        \u001b[38;5;34m76,803\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">465,231</span> (1.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m465,231\u001b[0m (1.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">465,231</span> (1.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m465,231\u001b[0m (1.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "learning_rate = 0.0001\n",
    "epochs = 8\n",
    "\n",
    "# Build your model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(192, 192, 3)),\n",
    "    layers.Conv2D(3, (1, 1), activation=\"linear\", name=\"Force_Grayscale\"),\n",
    "    layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.6),\n",
    "    layers.Dense(3, activation=\"softmax\")  # Make sure this matches the number of classes\n",
    "])\n",
    "\n",
    "# Compile with explicit learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 125ms/step - accuracy: 0.3885 - loss: 1.0810 - val_accuracy: 0.6616 - val_loss: 0.8918\n",
      "Epoch 2/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 129ms/step - accuracy: 0.6174 - loss: 0.8662 - val_accuracy: 0.7904 - val_loss: 0.6027\n",
      "Epoch 3/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 120ms/step - accuracy: 0.7107 - loss: 0.6914 - val_accuracy: 0.8169 - val_loss: 0.4731\n",
      "Epoch 4/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 116ms/step - accuracy: 0.7751 - loss: 0.5704 - val_accuracy: 0.8371 - val_loss: 0.4020\n",
      "Epoch 5/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 121ms/step - accuracy: 0.8072 - loss: 0.4930 - val_accuracy: 0.8712 - val_loss: 0.3497\n",
      "Epoch 6/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 126ms/step - accuracy: 0.8404 - loss: 0.4184 - val_accuracy: 0.9066 - val_loss: 0.2669\n",
      "Epoch 7/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 125ms/step - accuracy: 0.8658 - loss: 0.3578 - val_accuracy: 0.9217 - val_loss: 0.2315\n",
      "Epoch 8/8\n",
      "\u001b[1m990/990\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 124ms/step - accuracy: 0.8867 - loss: 0.2985 - val_accuracy: 0.9495 - val_loss: 0.1776\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 0.9561 - loss: 0.1719\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "model.evaluate(test_dataset)\n",
    "\n",
    "# Save the model to a file\n",
    "model.save(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Processing batch\n",
      "True labels (y_true): [1 2 1 2 1 1 0 1]\n",
      "Model predictions (raw): [[1.7230275e-01 7.9171073e-01 3.5986561e-02]\n",
      " [2.3894945e-04 2.6364075e-03 9.9712461e-01]\n",
      " [7.6284289e-04 9.9884355e-01 3.9357087e-04]\n",
      " [1.3903720e-02 1.9887578e-02 9.6620864e-01]\n",
      " [2.3225318e-04 9.9383634e-01 5.9313364e-03]\n",
      " [5.4613495e-04 9.9867189e-01 7.8196172e-04]\n",
      " [9.7638547e-01 2.1435356e-02 2.1791079e-03]\n",
      " [7.8771755e-02 5.0320733e-01 4.1802084e-01]]\n",
      "Predicted labels (argmax): [1 2 1 2 1 1 0 1]\n",
      "Step 2: Processing batch\n",
      "True labels (y_true): [0 1 0 2 0 2 1 2]\n",
      "Model predictions (raw): [[9.9861348e-01 1.3837907e-03 2.6994694e-06]\n",
      " [5.4941128e-04 9.9945003e-01 6.1528482e-07]\n",
      " [7.7320856e-01 1.5989593e-01 6.6895463e-02]\n",
      " [1.0263765e-02 5.8289464e-03 9.8390722e-01]\n",
      " [9.9974042e-01 2.4690700e-04 1.2612705e-05]\n",
      " [1.4678559e-02 3.0912636e-03 9.8223019e-01]\n",
      " [1.3745753e-02 8.0868369e-01 1.7757055e-01]\n",
      " [1.8673415e-01 3.0605111e-01 5.0721478e-01]]\n",
      "Predicted labels (argmax): [0 1 0 2 0 2 1 2]\n",
      "Step 3: Processing batch\n",
      "True labels (y_true): [1 0 1 0 1 1 1 2]\n",
      "Model predictions (raw): [[6.8776758e-04 9.9891257e-01 3.9971512e-04]\n",
      " [7.2938973e-01 2.0857172e-01 6.2038466e-02]\n",
      " [7.6273871e-03 9.8962855e-01 2.7440919e-03]\n",
      " [9.4281840e-01 5.6573715e-02 6.0780410e-04]\n",
      " [1.9688061e-01 4.0956387e-01 3.9355546e-01]\n",
      " [6.6475473e-02 8.5459787e-01 7.8926645e-02]\n",
      " [1.0411945e-02 9.8955405e-01 3.3984692e-05]\n",
      " [3.7314790e-01 3.0269551e-01 3.2415664e-01]]\n",
      "Predicted labels (argmax): [1 0 1 0 1 1 1 0]\n",
      "Step 4: Processing batch\n",
      "True labels (y_true): [1 1 0 2 0 2 0 2]\n",
      "Model predictions (raw): [[2.2654142e-03 9.9688172e-01 8.5285894e-04]\n",
      " [2.1800172e-01 4.4261292e-01 3.3938536e-01]\n",
      " [9.8079520e-01 2.6487806e-04 1.8939942e-02]\n",
      " [9.9752164e-03 2.4430670e-03 9.8758173e-01]\n",
      " [6.0935467e-01 5.9038620e-02 3.3160669e-01]\n",
      " [4.7270718e-04 3.9385742e-04 9.9913341e-01]\n",
      " [6.8620849e-01 2.7744180e-01 3.6349755e-02]\n",
      " [4.1509356e-02 1.2553769e-01 8.3295292e-01]]\n",
      "Predicted labels (argmax): [1 1 0 2 0 2 0 2]\n",
      "Step 5: Processing batch\n",
      "True labels (y_true): [0 1 1 1 2 2 0 0]\n",
      "Model predictions (raw): [[2.3744513e-01 6.3603193e-01 1.2652294e-01]\n",
      " [1.2310686e-02 9.8752266e-01 1.6670430e-04]\n",
      " [2.5047052e-01 6.0311663e-01 1.4641283e-01]\n",
      " [8.5976114e-03 9.7747678e-01 1.3925576e-02]\n",
      " [1.3498411e-02 1.6871195e-03 9.8481447e-01]\n",
      " [4.1607052e-02 8.0706298e-02 8.7768668e-01]\n",
      " [9.6789539e-01 3.0163668e-02 1.9409446e-03]\n",
      " [9.9962485e-01 3.6730384e-04 7.8831472e-06]]\n",
      "Predicted labels (argmax): [1 1 1 1 2 2 0 0]\n",
      "Step 6: Processing batch\n",
      "True labels (y_true): [0 0 1 2 0 2 1 2]\n",
      "Model predictions (raw): [[9.8598367e-01 8.5613178e-03 5.4550585e-03]\n",
      " [6.8794274e-01 2.5912297e-01 5.2934311e-02]\n",
      " [1.2149437e-01 8.7798834e-01 5.1730342e-04]\n",
      " [6.0038239e-02 8.7221600e-02 8.5274017e-01]\n",
      " [6.8124396e-01 1.6677779e-01 1.5197828e-01]\n",
      " [8.1306295e-03 1.5272187e-02 9.7659725e-01]\n",
      " [1.4793754e-01 7.2667551e-01 1.2538689e-01]\n",
      " [4.4370830e-02 3.4112908e-02 9.2151630e-01]]\n",
      "Predicted labels (argmax): [0 0 1 2 0 2 1 2]\n",
      "Step 7: Processing batch\n",
      "True labels (y_true): [1 2 2 1 1 1 2 0]\n",
      "Model predictions (raw): [[3.69386896e-02 7.71764576e-01 1.91296726e-01]\n",
      " [4.60386053e-02 1.12614855e-02 9.42699969e-01]\n",
      " [4.32375222e-02 9.23700407e-02 8.64392459e-01]\n",
      " [1.31806135e-01 8.36109340e-01 3.20845246e-02]\n",
      " [3.44054885e-02 9.42334175e-01 2.32602917e-02]\n",
      " [3.08425277e-01 6.49016142e-01 4.25585248e-02]\n",
      " [2.87314598e-03 5.74982204e-02 9.39628661e-01]\n",
      " [9.88707066e-01 1.59011033e-04 1.11339875e-02]]\n",
      "Predicted labels (argmax): [1 2 2 1 1 1 2 0]\n",
      "Step 8: Processing batch\n",
      "True labels (y_true): [0 0 1 0 1 1 0 2]\n",
      "Model predictions (raw): [[9.1681010e-01 8.3182856e-02 6.9854700e-06]\n",
      " [9.6664363e-01 7.0270882e-03 2.6329199e-02]\n",
      " [3.3411095e-03 9.9599212e-01 6.6682557e-04]\n",
      " [6.1060452e-01 2.3250360e-02 3.6614513e-01]\n",
      " [5.8738166e-04 9.9879992e-01 6.1263720e-04]\n",
      " [2.6875406e-03 9.7796488e-01 1.9347576e-02]\n",
      " [5.4982448e-01 1.5655741e-01 2.9361808e-01]\n",
      " [1.1019356e-02 3.9245975e-03 9.8505616e-01]]\n",
      "Predicted labels (argmax): [0 0 1 0 1 1 0 2]\n",
      "Step 9: Processing batch\n",
      "True labels (y_true): [1 0 2 1 2 1 0 2]\n",
      "Model predictions (raw): [[1.8439369e-02 9.5116556e-01 3.0395031e-02]\n",
      " [7.9244357e-01 2.0646115e-01 1.0952459e-03]\n",
      " [5.1230972e-04 9.1012036e-03 9.9038661e-01]\n",
      " [5.0156284e-04 9.9927491e-01 2.2353031e-04]\n",
      " [5.7241055e-03 8.5916609e-04 9.9341679e-01]\n",
      " [6.7983545e-02 9.2919111e-01 2.8253412e-03]\n",
      " [7.4758542e-01 1.3961336e-01 1.1280117e-01]\n",
      " [2.2455445e-02 8.1425542e-03 9.6940190e-01]]\n",
      "Predicted labels (argmax): [1 0 2 1 2 1 0 2]\n",
      "Step 10: Processing batch\n",
      "True labels (y_true): [1 1 2 0 2 2 0 0]\n",
      "Model predictions (raw): [[6.0301484e-04 9.9927908e-01 1.1794591e-04]\n",
      " [6.1035525e-02 7.7497590e-01 1.6398859e-01]\n",
      " [6.7398266e-04 3.3671679e-03 9.9595886e-01]\n",
      " [9.4728792e-01 1.8998340e-02 3.3713646e-02]\n",
      " [1.6492130e-03 3.9582041e-01 6.0253036e-01]\n",
      " [6.6575396e-04 4.5553497e-03 9.9477887e-01]\n",
      " [8.7677097e-01 8.8847607e-02 3.4381412e-02]\n",
      " [9.8474622e-01 9.3891053e-03 5.8645909e-03]]\n",
      "Predicted labels (argmax): [1 1 2 0 2 2 0 0]\n",
      "Step 11: Processing batch\n",
      "True labels (y_true): [2 2 2 2 2 2 2 2]\n",
      "Model predictions (raw): [[5.8533746e-01 8.1498750e-02 3.3316383e-01]\n",
      " [6.1641437e-01 2.5443992e-01 1.2914571e-01]\n",
      " [7.3517334e-01 1.7734905e-01 8.7477654e-02]\n",
      " [3.4670872e-03 7.1624137e-04 9.9581665e-01]\n",
      " [9.8943105e-04 1.5838423e-03 9.9742669e-01]\n",
      " [3.9704046e-01 3.6872587e-01 2.3423369e-01]\n",
      " [4.6965927e-03 7.9842340e-03 9.8731911e-01]\n",
      " [6.8586292e-03 2.5167514e-02 9.6797389e-01]]\n",
      "Predicted labels (argmax): [0 0 0 2 2 0 2 2]\n",
      "Step 12: Processing batch\n",
      "True labels (y_true): [0 2 0 1 0 1 2 1]\n",
      "Model predictions (raw): [[9.8003089e-01 1.8467892e-02 1.5011870e-03]\n",
      " [2.1961920e-03 1.4977038e-02 9.8282671e-01]\n",
      " [9.7302127e-01 1.5565577e-02 1.1413158e-02]\n",
      " [3.0633193e-02 9.3710870e-01 3.2258093e-02]\n",
      " [9.9761993e-01 2.3244349e-03 5.5699278e-05]\n",
      " [2.6630932e-02 9.5119393e-01 2.2175074e-02]\n",
      " [1.4211774e-02 1.7280746e-02 9.6850741e-01]\n",
      " [1.4071535e-02 9.7958243e-01 6.3460679e-03]]\n",
      "Predicted labels (argmax): [0 2 0 1 0 1 2 1]\n",
      "Step 13: Processing batch\n",
      "True labels (y_true): [1 2 2 2 0 1 0 1]\n",
      "Model predictions (raw): [[1.36313304e-01 7.86215067e-01 7.74716958e-02]\n",
      " [4.14113374e-03 2.72985306e-02 9.68560338e-01]\n",
      " [7.11150700e-03 1.22688599e-01 8.70199919e-01]\n",
      " [1.13010015e-02 3.24873850e-02 9.56211567e-01]\n",
      " [9.79116499e-01 1.88899436e-03 1.89945381e-02]\n",
      " [8.70086625e-02 8.54983747e-01 5.80075718e-02]\n",
      " [9.98866558e-01 1.06489472e-03 6.85935520e-05]\n",
      " [1.46969156e-02 9.41980541e-01 4.33224887e-02]]\n",
      "Predicted labels (argmax): [1 2 2 2 0 1 0 1]\n",
      "Step 14: Processing batch\n",
      "True labels (y_true): [1 2 2 0 1 1 1 1]\n",
      "Model predictions (raw): [[1.8739600e-02 9.8023123e-01 1.0291428e-03]\n",
      " [1.3646246e-03 2.5841895e-02 9.7279358e-01]\n",
      " [3.4363416e-01 1.1140442e-01 5.4496139e-01]\n",
      " [8.6503601e-01 1.4536591e-03 1.3351026e-01]\n",
      " [5.7841861e-04 9.9828523e-01 1.1363807e-03]\n",
      " [1.5649809e-04 9.9976128e-01 8.2198829e-05]\n",
      " [6.5318239e-03 9.9099308e-01 2.4750608e-03]\n",
      " [1.2277758e-02 9.8521477e-01 2.5074864e-03]]\n",
      "Predicted labels (argmax): [1 2 2 0 1 1 1 1]\n",
      "Step 15: Processing batch\n",
      "True labels (y_true): [0 0 2 0 2 0 1 1]\n",
      "Model predictions (raw): [[9.78552938e-01 1.08306007e-02 1.06164655e-02]\n",
      " [9.87357736e-01 1.25707351e-02 7.15727656e-05]\n",
      " [8.09541792e-02 1.97365463e-01 7.21680284e-01]\n",
      " [9.96894598e-01 2.97785108e-03 1.27551932e-04]\n",
      " [2.81329099e-02 8.58357921e-03 9.63283479e-01]\n",
      " [9.30110812e-01 8.58178455e-03 6.13073632e-02]\n",
      " [1.18537238e-02 9.86562967e-01 1.58332649e-03]\n",
      " [6.82042912e-02 9.04596090e-01 2.71996632e-02]]\n",
      "Predicted labels (argmax): [0 0 2 0 2 0 1 1]\n",
      "Step 16: Processing batch\n",
      "True labels (y_true): [1 0 0 2 2 2 0 0]\n",
      "Model predictions (raw): [[2.7043766e-03 9.9357283e-01 3.7228435e-03]\n",
      " [9.9836510e-01 9.5409219e-04 6.8080664e-04]\n",
      " [9.9616867e-01 3.3332368e-03 4.9805222e-04]\n",
      " [6.0458202e-03 2.9634624e-03 9.9099076e-01]\n",
      " [1.8031113e-02 3.4428105e-02 9.4754082e-01]\n",
      " [2.6249382e-01 1.6441879e-01 5.7308733e-01]\n",
      " [9.8327869e-01 1.6712101e-02 9.3142680e-06]\n",
      " [5.4442775e-01 1.9040006e-01 2.6517209e-01]]\n",
      "Predicted labels (argmax): [1 0 0 2 2 2 0 0]\n",
      "Step 17: Processing batch\n",
      "True labels (y_true): [2 2 0 1 0 2 0 1]\n",
      "Model predictions (raw): [[4.6606254e-04 7.1287528e-02 9.2824638e-01]\n",
      " [8.8608392e-02 6.1211523e-02 8.5018021e-01]\n",
      " [9.9928814e-01 6.3684786e-04 7.4991178e-05]\n",
      " [5.0301040e-03 9.9476308e-01 2.0689343e-04]\n",
      " [9.3728334e-01 5.9492033e-02 3.2246318e-03]\n",
      " [1.3651779e-01 7.9782866e-02 7.8369933e-01]\n",
      " [9.9087065e-01 9.4567158e-04 8.1837121e-03]\n",
      " [1.9536844e-01 7.8645599e-01 1.8175567e-02]]\n",
      "Predicted labels (argmax): [2 2 0 1 0 2 0 1]\n",
      "Step 18: Processing batch\n",
      "True labels (y_true): [0 0 0 0 1 0 0 1]\n",
      "Model predictions (raw): [[9.8035550e-01 1.8429149e-02 1.2153068e-03]\n",
      " [2.5699002e-01 1.3089511e-01 6.1211497e-01]\n",
      " [9.3489361e-01 6.4399652e-02 7.0670963e-04]\n",
      " [9.9836391e-01 9.5029484e-04 6.8580982e-04]\n",
      " [2.5807243e-02 9.5953786e-01 1.4654951e-02]\n",
      " [6.1923462e-01 1.3615540e-02 3.6714983e-01]\n",
      " [9.9923384e-01 5.9467409e-04 1.7150925e-04]\n",
      " [1.5361589e-01 8.0662006e-01 3.9764065e-02]]\n",
      "Predicted labels (argmax): [0 2 0 0 1 0 0 1]\n",
      "Step 19: Processing batch\n",
      "True labels (y_true): [0 2 2 0 0 2 1 0]\n",
      "Model predictions (raw): [[9.9138135e-01 5.6148116e-03 3.0038862e-03]\n",
      " [1.6861118e-02 1.3282932e-01 8.5030955e-01]\n",
      " [7.1537584e-02 4.4047423e-03 9.2405772e-01]\n",
      " [9.8339003e-01 1.4525684e-02 2.0843653e-03]\n",
      " [9.9997377e-01 2.6021964e-05 2.0027851e-07]\n",
      " [2.4923164e-02 6.5381345e-03 9.6853876e-01]\n",
      " [9.1551311e-02 8.8825834e-01 2.0190353e-02]\n",
      " [9.9997282e-01 2.4179641e-05 2.9572882e-06]]\n",
      "Predicted labels (argmax): [0 2 2 0 0 2 1 0]\n",
      "Step 20: Processing batch\n",
      "True labels (y_true): [2 1 0 2 2 2 0 1]\n",
      "Model predictions (raw): [[4.7435895e-02 1.1594386e-01 8.3662027e-01]\n",
      " [8.0139175e-02 5.4823518e-01 3.7162569e-01]\n",
      " [9.9945849e-01 5.3504982e-04 6.4473252e-06]\n",
      " [3.4230156e-04 4.1580400e-03 9.9549967e-01]\n",
      " [2.0438214e-03 5.7014231e-02 9.4094187e-01]\n",
      " [5.7802249e-02 7.2246477e-02 8.6995131e-01]\n",
      " [9.9843520e-01 1.2925758e-03 2.7218714e-04]\n",
      " [4.6623222e-04 9.9913126e-01 4.0247399e-04]]\n",
      "Predicted labels (argmax): [2 1 0 2 2 2 0 1]\n",
      "Step 21: Processing batch\n",
      "True labels (y_true): [2 2 1 1 2 1 0 2]\n",
      "Model predictions (raw): [[0.06383292 0.05919449 0.8769726 ]\n",
      " [0.16658184 0.10068987 0.73272824]\n",
      " [0.40971318 0.49297    0.0973169 ]\n",
      " [0.02794812 0.9654948  0.00655705]\n",
      " [0.00434115 0.01769139 0.9779674 ]\n",
      " [0.09188419 0.9046113  0.00350455]\n",
      " [0.8495853  0.04036435 0.1100504 ]\n",
      " [0.25569063 0.56212103 0.18218833]]\n",
      "Predicted labels (argmax): [2 2 1 1 2 1 0 1]\n",
      "Step 22: Processing batch\n",
      "True labels (y_true): [0 0 1 0 0 0 1 1]\n",
      "Model predictions (raw): [[9.4396347e-01 5.5426873e-02 6.0971978e-04]\n",
      " [9.9834991e-01 1.0666535e-03 5.8342179e-04]\n",
      " [7.1179871e-03 9.8748672e-01 5.3953179e-03]\n",
      " [9.9472189e-01 4.6581938e-03 6.1991380e-04]\n",
      " [9.9968410e-01 3.1005251e-04 5.8081700e-06]\n",
      " [3.3492777e-01 1.7406410e-02 6.4766586e-01]\n",
      " [6.1787397e-02 7.5722879e-01 1.8098380e-01]\n",
      " [7.2039897e-04 9.9918956e-01 8.9985442e-05]]\n",
      "Predicted labels (argmax): [0 0 1 0 0 2 1 1]\n",
      "Step 23: Processing batch\n",
      "True labels (y_true): [1 0 0 0 1 0 0 0]\n",
      "Model predictions (raw): [[4.7337901e-04 9.9872929e-01 7.9730374e-04]\n",
      " [9.8382139e-01 3.0003795e-03 1.3178248e-02]\n",
      " [9.9475819e-01 4.9700667e-03 2.7168277e-04]\n",
      " [8.0778778e-01 7.8735435e-03 1.8433867e-01]\n",
      " [5.2978047e-03 9.9462950e-01 7.2695533e-05]\n",
      " [7.9286265e-01 2.0643981e-01 6.9754373e-04]\n",
      " [9.9989891e-01 2.5864981e-06 9.8413679e-05]\n",
      " [9.9912089e-01 8.3217473e-04 4.6884023e-05]]\n",
      "Predicted labels (argmax): [1 0 0 0 1 0 0 0]\n",
      "Step 24: Processing batch\n",
      "True labels (y_true): [2 2 2 2 1 2 0 1]\n",
      "Model predictions (raw): [[4.0672350e-01 9.7532079e-02 4.9574441e-01]\n",
      " [1.3652952e-02 4.9484298e-02 9.3686271e-01]\n",
      " [2.3587583e-02 2.3189026e-01 7.4452209e-01]\n",
      " [1.5560146e-02 5.8457241e-03 9.7859418e-01]\n",
      " [2.1981399e-03 9.9753177e-01 2.7008433e-04]\n",
      " [4.0046172e-04 4.3918760e-03 9.9520773e-01]\n",
      " [8.5384703e-01 1.2484885e-01 2.1304101e-02]\n",
      " [5.7127601e-03 9.9124640e-01 3.0408497e-03]]\n",
      "Predicted labels (argmax): [2 2 2 2 1 2 0 1]\n",
      "Step 25: Processing batch\n",
      "True labels (y_true): [1 1 0 1 0 1 0 0]\n",
      "Model predictions (raw): [[4.99890512e-03 9.94801164e-01 1.99907838e-04]\n",
      " [5.20292185e-02 8.39729846e-01 1.08240955e-01]\n",
      " [6.11251712e-01 8.60431343e-02 3.02705109e-01]\n",
      " [4.04113270e-02 9.57823098e-01 1.76560995e-03]\n",
      " [8.31014335e-01 1.06835194e-01 6.21504374e-02]\n",
      " [1.83599535e-02 9.78932679e-01 2.70734634e-03]\n",
      " [4.74377513e-01 3.94470155e-01 1.31152347e-01]\n",
      " [9.92393494e-01 4.39339969e-03 3.21309688e-03]]\n",
      "Predicted labels (argmax): [1 1 0 1 0 1 0 0]\n",
      "Step 26: Processing batch\n",
      "True labels (y_true): [1 1 1 1 1 0 1 1]\n",
      "Model predictions (raw): [[1.1319066e-01 6.4923102e-01 2.3757832e-01]\n",
      " [5.7137925e-02 6.6866392e-01 2.7419817e-01]\n",
      " [5.1394012e-03 9.8866487e-01 6.1957482e-03]\n",
      " [1.5904781e-01 7.4981099e-01 9.1141246e-02]\n",
      " [5.4352826e-05 9.9989522e-01 5.0415587e-05]\n",
      " [8.9641094e-01 9.2351794e-02 1.1237353e-02]\n",
      " [6.6513411e-04 9.9817467e-01 1.1602300e-03]\n",
      " [1.5784960e-02 9.8245239e-01 1.7626684e-03]]\n",
      "Predicted labels (argmax): [1 1 1 1 1 0 1 1]\n",
      "Step 27: Processing batch\n",
      "True labels (y_true): [0 2 0 2 0 1 2 2]\n",
      "Model predictions (raw): [[9.8017853e-01 4.1168093e-04 1.9409839e-02]\n",
      " [8.4104456e-02 1.9062671e-03 9.1398925e-01]\n",
      " [9.9748248e-01 2.4961806e-03 2.1363285e-05]\n",
      " [6.4746817e-03 4.6278842e-04 9.9306256e-01]\n",
      " [4.3044010e-01 8.4982365e-03 5.6106156e-01]\n",
      " [2.9132577e-02 9.6196729e-01 8.9001236e-03]\n",
      " [1.4641243e-01 4.8688626e-01 3.6670130e-01]\n",
      " [8.7574311e-04 4.2419271e-03 9.9488235e-01]]\n",
      "Predicted labels (argmax): [0 2 0 2 2 1 1 2]\n",
      "Step 28: Processing batch\n",
      "True labels (y_true): [1 1 1 2 0 0 2 2]\n",
      "Model predictions (raw): [[7.9857081e-02 8.6433560e-01 5.5807304e-02]\n",
      " [2.1551888e-02 9.7800964e-01 4.3838640e-04]\n",
      " [3.3798520e-04 9.9943215e-01 2.2984362e-04]\n",
      " [2.7085762e-02 6.7425959e-02 9.0548837e-01]\n",
      " [9.9947602e-01 3.4847547e-04 1.7545700e-04]\n",
      " [9.7778487e-01 1.0368154e-02 1.1846982e-02]\n",
      " [1.5676638e-02 5.7137022e-03 9.7860956e-01]\n",
      " [3.5388850e-02 6.1422452e-02 9.0318859e-01]]\n",
      "Predicted labels (argmax): [1 1 1 2 0 0 2 2]\n",
      "Step 29: Processing batch\n",
      "True labels (y_true): [0 0 2 1 1 2 2 2]\n",
      "Model predictions (raw): [[0.98700744 0.00788309 0.00510945]\n",
      " [0.98536116 0.00954516 0.00509376]\n",
      " [0.17602381 0.41013828 0.41383797]\n",
      " [0.01600383 0.95376605 0.03023009]\n",
      " [0.00124768 0.9970481  0.00170422]\n",
      " [0.03084379 0.06715693 0.90199924]\n",
      " [0.12870093 0.10016294 0.77113616]\n",
      " [0.30385104 0.02350538 0.6726436 ]]\n",
      "Predicted labels (argmax): [0 0 2 1 1 2 2 2]\n",
      "Step 30: Processing batch\n",
      "True labels (y_true): [1 1 0 0 0 0 0 0]\n",
      "Model predictions (raw): [[2.0810389e-03 9.9761629e-01 3.0268871e-04]\n",
      " [6.5676897e-05 9.9989581e-01 3.8486232e-05]\n",
      " [5.4018277e-01 8.7803327e-02 3.7201387e-01]\n",
      " [9.9984682e-01 1.4221091e-05 1.3903012e-04]\n",
      " [6.0857743e-01 2.7210721e-01 1.1931537e-01]\n",
      " [9.9908113e-01 5.5989431e-04 3.5895733e-04]\n",
      " [8.8715178e-01 8.4546685e-02 2.8301563e-02]\n",
      " [9.9995613e-01 4.3780936e-05 1.6710813e-07]]\n",
      "Predicted labels (argmax): [1 1 0 0 0 0 0 0]\n",
      "Step 31: Processing batch\n",
      "True labels (y_true): [1 2 1 0 0 0 2 0]\n",
      "Model predictions (raw): [[9.9340357e-02 8.9750993e-01 3.1497222e-03]\n",
      " [3.0014489e-03 3.3424252e-03 9.9365616e-01]\n",
      " [1.6475547e-03 9.5218533e-01 4.6167076e-02]\n",
      " [9.9866986e-01 1.3258449e-03 4.2471615e-06]\n",
      " [5.9246874e-01 1.8380651e-02 3.8915053e-01]\n",
      " [7.7770537e-01 2.1879363e-01 3.5010222e-03]\n",
      " [1.3825539e-03 8.6839776e-03 9.8993343e-01]\n",
      " [9.9650133e-01 3.1258236e-03 3.7285127e-04]]\n",
      "Predicted labels (argmax): [1 2 1 0 0 0 2 0]\n",
      "Step 32: Processing batch\n",
      "True labels (y_true): [1 2 0 0 1 1 2 0]\n",
      "Model predictions (raw): [[3.1699517e-03 9.9642050e-01 4.0960280e-04]\n",
      " [1.3083038e-02 1.0832006e-02 9.7608495e-01]\n",
      " [9.8695332e-01 5.8669075e-03 7.1797175e-03]\n",
      " [9.6515447e-01 2.0133473e-02 1.4712161e-02]\n",
      " [2.2173626e-03 9.9728394e-01 4.9870752e-04]\n",
      " [1.0117718e-03 9.9793613e-01 1.0521625e-03]\n",
      " [4.5096283e-03 1.9664865e-02 9.7582555e-01]\n",
      " [9.6798611e-01 1.6239945e-02 1.5774030e-02]]\n",
      "Predicted labels (argmax): [1 2 0 0 1 1 2 0]\n",
      "Step 33: Processing batch\n",
      "True labels (y_true): [2 0 0 2 2 2 0 1]\n",
      "Model predictions (raw): [[1.0870577e-02 6.6817612e-03 9.8244768e-01]\n",
      " [2.4059726e-01 6.9588888e-01 6.3513860e-02]\n",
      " [9.9132884e-01 6.0432558e-03 2.6278649e-03]\n",
      " [1.5949864e-03 4.0767039e-04 9.9799722e-01]\n",
      " [1.5735831e-02 3.5682298e-02 9.4858181e-01]\n",
      " [3.2250798e-01 7.7282742e-02 6.0020930e-01]\n",
      " [9.9882716e-01 4.8427767e-04 6.8862492e-04]\n",
      " [9.5940538e-04 9.9901104e-01 2.9575773e-05]]\n",
      "Predicted labels (argmax): [2 1 0 2 2 2 0 1]\n",
      "Step 34: Processing batch\n",
      "True labels (y_true): [0 1 2 2 1 1 2 2]\n",
      "Model predictions (raw): [[9.6479470e-01 3.9969380e-03 3.1208463e-02]\n",
      " [3.6817526e-03 9.9354821e-01 2.7700434e-03]\n",
      " [4.5422290e-05 7.2370446e-04 9.9923086e-01]\n",
      " [3.1499840e-02 1.3513965e-02 9.5498616e-01]\n",
      " [9.3414776e-02 8.0952591e-01 9.7059324e-02]\n",
      " [9.0707997e-03 9.8832428e-01 2.6049209e-03]\n",
      " [4.5322630e-01 9.9427812e-02 4.4734591e-01]\n",
      " [5.5821836e-03 3.8013395e-02 9.5640445e-01]]\n",
      "Predicted labels (argmax): [0 1 2 2 1 1 0 2]\n",
      "Step 35: Processing batch\n",
      "True labels (y_true): [2 1 1 0 1 0 1 2]\n",
      "Model predictions (raw): [[8.5352886e-01 6.8870232e-02 7.7600896e-02]\n",
      " [3.7478225e-04 9.9960524e-01 2.0049862e-05]\n",
      " [1.5017812e-02 9.8477477e-01 2.0736340e-04]\n",
      " [6.9461328e-01 1.0002452e-01 2.0536216e-01]\n",
      " [1.7220885e-01 8.0733556e-01 2.0455627e-02]\n",
      " [4.4038826e-01 3.3334491e-01 2.2626683e-01]\n",
      " [1.6269009e-01 8.0525988e-01 3.2050062e-02]\n",
      " [4.4893514e-02 2.4323154e-02 9.3078339e-01]]\n",
      "Predicted labels (argmax): [0 1 1 0 1 0 1 2]\n",
      "Step 36: Processing batch\n",
      "True labels (y_true): [0 1 1 1 2 2 1 0]\n",
      "Model predictions (raw): [[9.9312496e-01 6.7523629e-03 1.2264133e-04]\n",
      " [3.1165004e-01 6.1561787e-01 7.2732091e-02]\n",
      " [1.1080991e-03 9.9870944e-01 1.8249435e-04]\n",
      " [2.3336087e-03 9.9737382e-01 2.9261818e-04]\n",
      " [1.3433970e-02 1.5751105e-02 9.7081494e-01]\n",
      " [1.3653802e-04 7.5636746e-04 9.9910706e-01]\n",
      " [1.8953878e-04 9.9964547e-01 1.6503828e-04]\n",
      " [9.6206349e-01 3.7702769e-02 2.3376168e-04]]\n",
      "Predicted labels (argmax): [0 1 1 1 2 2 1 0]\n",
      "Step 37: Processing batch\n",
      "True labels (y_true): [2 2 2 1 2 2 2 1]\n",
      "Model predictions (raw): [[9.3511567e-02 3.9611527e-01 5.1037318e-01]\n",
      " [1.0513923e-02 1.5729794e-03 9.8791307e-01]\n",
      " [4.4954639e-02 8.2039321e-03 9.4684142e-01]\n",
      " [6.0496341e-02 9.0068549e-01 3.8818214e-02]\n",
      " [3.4908784e-04 6.6837738e-03 9.9296713e-01]\n",
      " [1.9416386e-04 4.5768544e-04 9.9934810e-01]\n",
      " [2.6478632e-03 1.4770578e-04 9.9720436e-01]\n",
      " [5.3059034e-02 9.4678736e-01 1.5358132e-04]]\n",
      "Predicted labels (argmax): [2 2 2 1 2 2 2 1]\n",
      "Step 38: Processing batch\n",
      "True labels (y_true): [2 1 1 1 2 1 0 0]\n",
      "Model predictions (raw): [[2.6821285e-03 3.0138236e-02 9.6717960e-01]\n",
      " [2.5994137e-03 9.9659157e-01 8.0899621e-04]\n",
      " [3.7526661e-05 9.9990976e-01 5.2744574e-05]\n",
      " [4.0476489e-01 5.3228372e-01 6.2951364e-02]\n",
      " [8.1136534e-03 1.4557340e-02 9.7732896e-01]\n",
      " [2.8477530e-03 9.9695194e-01 2.0034635e-04]\n",
      " [8.2117379e-01 1.6335711e-01 1.5469155e-02]\n",
      " [9.0969384e-01 5.9770681e-02 3.0535402e-02]]\n",
      "Predicted labels (argmax): [2 1 1 1 2 1 0 0]\n",
      "Step 39: Processing batch\n",
      "True labels (y_true): [2 1 0 1 2 2 0 1]\n",
      "Model predictions (raw): [[6.15021354e-03 3.45071033e-03 9.90399063e-01]\n",
      " [8.89566615e-02 8.30710948e-01 8.03324133e-02]\n",
      " [8.84331524e-01 2.18819100e-02 9.37865153e-02]\n",
      " [1.68696191e-04 9.99729335e-01 1.02003345e-04]\n",
      " [3.37216146e-02 5.64690074e-03 9.60631490e-01]\n",
      " [4.59762709e-03 5.09531889e-03 9.90307093e-01]\n",
      " [6.97816551e-01 7.46537058e-04 3.01436841e-01]\n",
      " [2.52550322e-04 9.99737084e-01 1.03011498e-05]]\n",
      "Predicted labels (argmax): [2 1 0 1 2 2 0 1]\n",
      "Step 40: Processing batch\n",
      "True labels (y_true): [1 1 2 1 2 2 0 0]\n",
      "Model predictions (raw): [[6.2964032e-03 9.8226351e-01 1.1440100e-02]\n",
      " [4.6918429e-03 9.9510682e-01 2.0133497e-04]\n",
      " [2.1948938e-03 5.4966360e-03 9.9230838e-01]\n",
      " [1.9915085e-04 9.9969411e-01 1.0673998e-04]\n",
      " [2.8876310e-02 4.5394078e-03 9.6658427e-01]\n",
      " [1.1798955e-02 4.8295800e-03 9.8337144e-01]\n",
      " [9.7259665e-01 2.5852574e-02 1.5508201e-03]\n",
      " [9.9821067e-01 1.2633298e-03 5.2601926e-04]]\n",
      "Predicted labels (argmax): [1 1 2 1 2 2 0 0]\n",
      "Step 41: Processing batch\n",
      "True labels (y_true): [1 1 0 2 2 2 2 1]\n",
      "Model predictions (raw): [[3.98721593e-03 9.94837701e-01 1.17508671e-03]\n",
      " [2.96019902e-03 9.96659636e-01 3.80116835e-04]\n",
      " [9.48308468e-01 3.67667601e-02 1.49247414e-02]\n",
      " [1.82159722e-01 5.84635317e-01 2.33205006e-01]\n",
      " [2.00015008e-02 3.47658060e-02 9.45232749e-01]\n",
      " [9.40455124e-03 1.11112907e-03 9.89484251e-01]\n",
      " [4.28113015e-03 1.54199721e-02 9.80298936e-01]\n",
      " [2.63743307e-02 8.64023864e-01 1.09601796e-01]]\n",
      "Predicted labels (argmax): [1 1 0 1 2 2 2 1]\n",
      "Step 42: Processing batch\n",
      "True labels (y_true): [1 0 1 2 1 0 2 1]\n",
      "Model predictions (raw): [[2.4565519e-01 6.4850539e-01 1.0583936e-01]\n",
      " [9.5675468e-01 3.7202612e-02 6.0426900e-03]\n",
      " [9.2880063e-02 8.6033517e-01 4.6784695e-02]\n",
      " [2.7851660e-02 6.7857921e-02 9.0429038e-01]\n",
      " [3.3507179e-03 9.9600130e-01 6.4794021e-04]\n",
      " [6.5663433e-01 6.5650746e-02 2.7771491e-01]\n",
      " [4.3075413e-02 1.9497409e-01 7.6195043e-01]\n",
      " [7.3371209e-02 9.2594308e-01 6.8576698e-04]]\n",
      "Predicted labels (argmax): [1 0 1 2 1 0 2 1]\n",
      "Step 43: Processing batch\n",
      "True labels (y_true): [1 0 2 2 1 1 2 0]\n",
      "Model predictions (raw): [[4.4785466e-02 5.3119000e-02 9.0209556e-01]\n",
      " [9.9616891e-01 8.2602660e-04 3.0050799e-03]\n",
      " [1.4585541e-03 2.0316190e-03 9.9650985e-01]\n",
      " [1.2472838e-03 5.1950540e-02 9.4680214e-01]\n",
      " [1.1964835e-01 8.7771797e-01 2.6336273e-03]\n",
      " [6.7249566e-05 9.9992132e-01 1.1418801e-05]\n",
      " [2.3622271e-01 8.0424463e-03 7.5573480e-01]\n",
      " [9.9937695e-01 6.1289856e-04 1.0125270e-05]]\n",
      "Predicted labels (argmax): [2 0 2 2 1 1 2 0]\n",
      "Step 44: Processing batch\n",
      "True labels (y_true): [1 0 2 1 2 2 2 2]\n",
      "Model predictions (raw): [[2.8785786e-01 6.9781649e-01 1.4325579e-02]\n",
      " [9.9061513e-01 8.1121996e-03 1.2726490e-03]\n",
      " [4.6806922e-03 2.8296923e-02 9.6702242e-01]\n",
      " [2.0925915e-03 9.9744415e-01 4.6329532e-04]\n",
      " [1.6130994e-04 1.5733556e-03 9.9826533e-01]\n",
      " [1.0363103e-02 2.5405012e-02 9.6423185e-01]\n",
      " [2.3040047e-02 1.9325076e-01 7.8370923e-01]\n",
      " [8.9848777e-03 4.7713686e-02 9.4330144e-01]]\n",
      "Predicted labels (argmax): [1 0 2 1 2 2 2 2]\n",
      "Step 45: Processing batch\n",
      "True labels (y_true): [0 2 1 1 0 2 2 2]\n",
      "Model predictions (raw): [[9.89302456e-01 1.00794155e-02 6.18091144e-04]\n",
      " [1.52772209e-02 1.50851458e-02 9.69637573e-01]\n",
      " [2.03436017e-02 9.76326168e-01 3.33020021e-03]\n",
      " [6.40094106e-04 9.98352170e-01 1.00775959e-03]\n",
      " [9.94187236e-01 5.75519307e-03 5.75792074e-05]\n",
      " [3.37887555e-03 3.64861488e-02 9.60134983e-01]\n",
      " [1.02730840e-02 4.22353158e-03 9.85503316e-01]\n",
      " [7.29962951e-03 9.25005879e-03 9.83450294e-01]]\n",
      "Predicted labels (argmax): [0 2 1 1 0 2 2 2]\n",
      "Step 46: Processing batch\n",
      "True labels (y_true): [1 0 0 2 2 1 2 0]\n",
      "Model predictions (raw): [[1.12289704e-01 8.81459832e-01 6.25045551e-03]\n",
      " [3.34530324e-01 6.48054719e-01 1.74150076e-02]\n",
      " [9.98930991e-01 8.75149504e-04 1.93855682e-04]\n",
      " [1.17018272e-03 9.86282248e-03 9.88967001e-01]\n",
      " [3.65318283e-02 2.96003628e-03 9.60508108e-01]\n",
      " [5.10401698e-03 9.94351745e-01 5.44208218e-04]\n",
      " [9.12049843e-04 2.28620274e-03 9.96801734e-01]\n",
      " [9.30137515e-01 3.03675942e-02 3.94949168e-02]]\n",
      "Predicted labels (argmax): [1 1 0 2 2 1 2 0]\n",
      "Step 47: Processing batch\n",
      "True labels (y_true): [2 2 2 1 0 1 0 1]\n",
      "Model predictions (raw): [[1.29709348e-01 1.43874615e-01 7.26416051e-01]\n",
      " [2.88194744e-03 5.22380322e-03 9.91894186e-01]\n",
      " [3.02346074e-03 2.66613681e-02 9.70315099e-01]\n",
      " [6.58813491e-03 9.92473364e-01 9.38559533e-04]\n",
      " [8.84356618e-01 1.10712938e-01 4.93049901e-03]\n",
      " [1.11059226e-01 8.24333012e-01 6.46077916e-02]\n",
      " [7.81738520e-01 2.16083825e-01 2.17755651e-03]\n",
      " [2.81758338e-01 6.44334078e-01 7.39075765e-02]]\n",
      "Predicted labels (argmax): [2 2 2 1 0 1 0 1]\n",
      "Step 48: Processing batch\n",
      "True labels (y_true): [1 0 0 2 1 1 2 0]\n",
      "Model predictions (raw): [[9.3571022e-03 9.8838764e-01 2.2552765e-03]\n",
      " [8.7396592e-01 1.1275185e-01 1.3282183e-02]\n",
      " [9.9960333e-01 1.2673340e-04 2.6993608e-04]\n",
      " [9.5700592e-02 8.0667950e-02 8.2363153e-01]\n",
      " [1.1828083e-01 8.0505770e-01 7.6661490e-02]\n",
      " [1.2804816e-02 9.7513926e-01 1.2055989e-02]\n",
      " [3.9401925e-03 4.0154792e-03 9.9204433e-01]\n",
      " [9.9082899e-01 9.1293529e-03 4.1714404e-05]]\n",
      "Predicted labels (argmax): [1 0 0 2 1 1 2 0]\n",
      "Step 49: Processing batch\n",
      "True labels (y_true): [2 2 2 0 0 0 1 0]\n",
      "Model predictions (raw): [[7.5551353e-02 9.7500153e-02 8.2694846e-01]\n",
      " [2.4600124e-03 5.8962768e-03 9.9164373e-01]\n",
      " [3.1549584e-02 1.9521616e-02 9.4892877e-01]\n",
      " [9.7558016e-01 8.9625660e-03 1.5457353e-02]\n",
      " [9.9800605e-01 1.9745082e-03 1.9493375e-05]\n",
      " [9.9451506e-01 3.4780591e-03 2.0069312e-03]\n",
      " [1.0370264e-01 8.9289784e-01 3.3995425e-03]\n",
      " [9.8216724e-01 5.7000364e-03 1.2132600e-02]]\n",
      "Predicted labels (argmax): [2 2 2 0 0 0 1 0]\n",
      "Step 50: Processing batch\n",
      "True labels (y_true): [1 1 2 0 2 0 0 0]\n",
      "Model predictions (raw): [[1.2598811e-01 6.6882479e-01 2.0518705e-01]\n",
      " [7.0056673e-03 9.9242276e-01 5.7157816e-04]\n",
      " [3.2549188e-02 1.1472612e-01 8.5272467e-01]\n",
      " [9.9961096e-01 2.5287271e-04 1.3624688e-04]\n",
      " [1.0439924e-02 1.1134722e-04 9.8944879e-01]\n",
      " [8.6308342e-01 4.8753060e-02 8.8163503e-02]\n",
      " [6.0470724e-01 3.4743997e-01 4.7852818e-02]\n",
      " [2.3818476e-01 6.9392842e-01 6.7886747e-02]]\n",
      "Predicted labels (argmax): [1 1 2 0 2 0 0 1]\n",
      "Step 51: Processing batch\n",
      "True labels (y_true): [1 0 0 1 0 0 2 1]\n",
      "Model predictions (raw): [[1.0304797e-01 8.9536822e-01 1.5838232e-03]\n",
      " [2.4878851e-01 3.2511357e-02 7.1870011e-01]\n",
      " [7.7137721e-01 2.2300497e-01 5.6179147e-03]\n",
      " [4.2789557e-04 9.9855012e-01 1.0219400e-03]\n",
      " [8.8684505e-01 7.1322648e-03 1.0602261e-01]\n",
      " [9.2983514e-01 1.6183840e-02 5.3981073e-02]\n",
      " [1.3876475e-03 2.5114886e-02 9.7349757e-01]\n",
      " [1.4536537e-01 8.1591600e-01 3.8718604e-02]]\n",
      "Predicted labels (argmax): [1 2 0 1 0 0 2 1]\n",
      "Step 52: Processing batch\n",
      "True labels (y_true): [2 2 2 0 1 2 0 2]\n",
      "Model predictions (raw): [[8.9435615e-03 3.5674814e-02 9.5538163e-01]\n",
      " [1.8796708e-01 1.3448212e-01 6.7755079e-01]\n",
      " [7.0092946e-02 3.7272915e-02 8.9263415e-01]\n",
      " [9.4898254e-01 4.9967553e-02 1.0499846e-03]\n",
      " [2.1021327e-02 9.7830439e-01 6.7422312e-04]\n",
      " [5.0969766e-03 1.5304534e-02 9.7959852e-01]\n",
      " [9.5067543e-01 4.7609080e-02 1.7155048e-03]\n",
      " [3.6117252e-02 1.3143653e-02 9.5073903e-01]]\n",
      "Predicted labels (argmax): [2 2 2 0 1 2 0 2]\n",
      "Step 53: Processing batch\n",
      "True labels (y_true): [2 1 0 2 0 1 1 1]\n",
      "Model predictions (raw): [[3.1011598e-02 3.3843875e-01 6.3054967e-01]\n",
      " [2.2871439e-04 9.9926692e-01 5.0439365e-04]\n",
      " [9.5103782e-01 2.4226615e-02 2.4735579e-02]\n",
      " [6.7341090e-03 5.8064666e-03 9.8745942e-01]\n",
      " [9.5118046e-01 3.3702996e-02 1.5116568e-02]\n",
      " [2.0816714e-01 4.3734238e-01 3.5449043e-01]\n",
      " [1.2470953e-03 9.9860817e-01 1.4477778e-04]\n",
      " [4.1829706e-03 9.8989350e-01 5.9234826e-03]]\n",
      "Predicted labels (argmax): [2 1 0 2 0 1 1 1]\n",
      "Step 54: Processing batch\n",
      "True labels (y_true): [2 2 2 2 0 2 2 0]\n",
      "Model predictions (raw): [[1.7272897e-02 2.2886503e-03 9.8043847e-01]\n",
      " [8.4502035e-04 2.8948537e-03 9.9626017e-01]\n",
      " [1.7658444e-02 3.6444918e-03 9.7869706e-01]\n",
      " [5.5789781e-01 5.7437900e-02 3.8466427e-01]\n",
      " [8.3240235e-01 1.4021126e-02 1.5357655e-01]\n",
      " [2.2963015e-03 3.7954620e-03 9.9390817e-01]\n",
      " [4.3352805e-03 1.3534587e-02 9.8213011e-01]\n",
      " [9.0874946e-01 4.4824123e-02 4.6426374e-02]]\n",
      "Predicted labels (argmax): [2 2 2 0 0 2 2 0]\n",
      "Step 55: Processing batch\n",
      "True labels (y_true): [1 1 0 2 2 0 2 1]\n",
      "Model predictions (raw): [[2.8015776e-03 9.9712437e-01 7.3990384e-05]\n",
      " [2.5474776e-02 8.8531035e-01 8.9214839e-02]\n",
      " [8.6378962e-01 1.2058373e-01 1.5626715e-02]\n",
      " [4.7844943e-02 1.3560252e-01 8.1655252e-01]\n",
      " [9.0217151e-02 5.9834756e-02 8.4994811e-01]\n",
      " [9.5574391e-01 4.3000907e-02 1.2551544e-03]\n",
      " [2.8230598e-02 5.7920586e-02 9.1384876e-01]\n",
      " [1.1098811e-01 8.8736010e-01 1.6518342e-03]]\n",
      "Predicted labels (argmax): [1 1 0 2 2 0 2 1]\n",
      "Step 56: Processing batch\n",
      "True labels (y_true): [2 0 0 2 2 0 2 0]\n",
      "Model predictions (raw): [[5.7519227e-03 1.1282605e-02 9.8296541e-01]\n",
      " [9.9967492e-01 2.7040971e-04 5.4683394e-05]\n",
      " [9.1227347e-01 5.8461733e-02 2.9264750e-02]\n",
      " [4.8608235e-03 2.0706953e-02 9.7443229e-01]\n",
      " [1.2159171e-02 4.0254809e-02 9.4758606e-01]\n",
      " [8.5808623e-01 7.8042112e-02 6.3871667e-02]\n",
      " [3.3097580e-02 5.2475829e-02 9.1442657e-01]\n",
      " [7.6795793e-01 1.5687445e-01 7.5167678e-02]]\n",
      "Predicted labels (argmax): [2 0 0 2 2 0 2 0]\n",
      "Step 57: Processing batch\n",
      "True labels (y_true): [0 0 2 2 1 0 1 0]\n",
      "Model predictions (raw): [[9.8335880e-01 1.2364360e-02 4.2768205e-03]\n",
      " [9.9453509e-01 3.5772815e-03 1.8877017e-03]\n",
      " [1.7316891e-02 4.2291465e-03 9.7845399e-01]\n",
      " [3.1426076e-03 2.4244643e-03 9.9443287e-01]\n",
      " [2.1419558e-01 5.7974607e-01 2.0605834e-01]\n",
      " [9.2302954e-01 7.6610520e-02 3.5990105e-04]\n",
      " [4.3994725e-02 9.5460939e-01 1.3958456e-03]\n",
      " [9.1703480e-01 6.9294069e-03 7.6035827e-02]]\n",
      "Predicted labels (argmax): [0 0 2 2 1 0 1 0]\n",
      "Step 58: Processing batch\n",
      "True labels (y_true): [2 2 0 1 0 2 1 0]\n",
      "Model predictions (raw): [[1.3332704e-01 4.2528890e-02 8.2414407e-01]\n",
      " [1.5245780e-03 2.3162695e-02 9.7531271e-01]\n",
      " [9.5463794e-01 1.5291061e-02 3.0070910e-02]\n",
      " [2.3035437e-01 6.7679065e-01 9.2854984e-02]\n",
      " [2.7089551e-01 2.1864779e-01 5.1045674e-01]\n",
      " [6.0523453e-04 2.0411222e-04 9.9919063e-01]\n",
      " [6.1805936e-04 9.9916160e-01 2.2037375e-04]\n",
      " [8.0657816e-01 8.7549882e-03 1.8466690e-01]]\n",
      "Predicted labels (argmax): [2 2 0 1 2 2 1 0]\n",
      "Step 59: Processing batch\n",
      "True labels (y_true): [2 1 1 0 2 1 0 0]\n",
      "Model predictions (raw): [[6.83160918e-03 1.68069508e-02 9.76361513e-01]\n",
      " [1.83026027e-03 9.96337891e-01 1.83181616e-03]\n",
      " [8.77458253e-04 9.97128904e-01 1.99363567e-03]\n",
      " [6.33341372e-01 3.28226030e-01 3.84326391e-02]\n",
      " [2.33722046e-01 5.32401085e-01 2.33876869e-01]\n",
      " [1.37743145e-01 7.55613744e-01 1.06643125e-01]\n",
      " [2.64290422e-01 7.29586840e-01 6.12271484e-03]\n",
      " [9.98266280e-01 1.68117811e-03 5.26111980e-05]]\n",
      "Predicted labels (argmax): [2 1 1 0 1 1 1 0]\n",
      "Step 60: Processing batch\n",
      "True labels (y_true): [2 0 0 0 0 2 2 2]\n",
      "Model predictions (raw): [[3.2692179e-02 4.8266344e-02 9.1904145e-01]\n",
      " [9.9961972e-01 2.8424145e-04 9.5991119e-05]\n",
      " [9.8915559e-01 1.1684147e-03 9.6760467e-03]\n",
      " [9.9604166e-01 1.4967400e-03 2.4616206e-03]\n",
      " [8.6943305e-01 9.1224298e-02 3.9342709e-02]\n",
      " [2.2634652e-02 2.4238163e-01 7.3498362e-01]\n",
      " [1.9935616e-03 9.1466919e-02 9.0653962e-01]\n",
      " [1.4591688e-02 2.6772082e-02 9.5863616e-01]]\n",
      "Predicted labels (argmax): [2 0 0 0 0 2 2 2]\n",
      "Step 61: Processing batch\n",
      "True labels (y_true): [1 2 0 1 0 1 2 2]\n",
      "Model predictions (raw): [[2.5879886e-02 9.4914424e-01 2.4975872e-02]\n",
      " [1.1082878e-01 4.4114817e-02 8.4505641e-01]\n",
      " [9.9735862e-01 1.1158179e-03 1.5254812e-03]\n",
      " [6.9284014e-02 8.4871405e-01 8.2001902e-02]\n",
      " [9.0827894e-01 9.1684923e-02 3.6193051e-05]\n",
      " [7.9351336e-02 8.9889890e-01 2.1749817e-02]\n",
      " [7.0589893e-02 2.7363762e-01 6.5577251e-01]\n",
      " [3.8888372e-02 2.6365004e-03 9.5847517e-01]]\n",
      "Predicted labels (argmax): [1 2 0 1 0 1 2 2]\n",
      "Step 62: Processing batch\n",
      "True labels (y_true): [2 1 1 0 2 0 1 1]\n",
      "Model predictions (raw): [[5.87214008e-02 3.09037883e-02 9.10374761e-01]\n",
      " [1.78156830e-02 9.77548420e-01 4.63588536e-03]\n",
      " [7.90309235e-02 9.03268278e-01 1.77007988e-02]\n",
      " [9.84841049e-01 1.13242362e-02 3.83467111e-03]\n",
      " [1.04114585e-01 1.15220901e-02 8.84363353e-01]\n",
      " [9.97861326e-01 2.04060390e-03 9.80681507e-05]\n",
      " [2.14883452e-03 9.93356287e-01 4.49483236e-03]\n",
      " [1.18530706e-01 8.61331940e-01 2.01374087e-02]]\n",
      "Predicted labels (argmax): [2 1 1 0 2 0 1 1]\n",
      "Step 63: Processing batch\n",
      "True labels (y_true): [2 0 2 0 0 1 2 0]\n",
      "Model predictions (raw): [[1.6557645e-02 1.0229439e-02 9.7321284e-01]\n",
      " [8.2655907e-01 8.2870863e-02 9.0570174e-02]\n",
      " [4.6473495e-03 5.9205219e-03 9.8943222e-01]\n",
      " [9.9077165e-01 2.9365970e-03 6.2918495e-03]\n",
      " [9.9585378e-01 2.3077759e-03 1.8384656e-03]\n",
      " [3.2056009e-03 9.9389029e-01 2.9040747e-03]\n",
      " [9.7152553e-03 8.9883814e-03 9.8129636e-01]\n",
      " [9.9919385e-01 5.9519918e-04 2.1093040e-04]]\n",
      "Predicted labels (argmax): [2 0 2 0 0 1 2 0]\n",
      "Step 64: Processing batch\n",
      "True labels (y_true): [2 2 1 0 1 1 2 2]\n",
      "Model predictions (raw): [[4.6102285e-02 3.7293758e-02 9.1660392e-01]\n",
      " [4.0566167e-05 1.0659080e-03 9.9889356e-01]\n",
      " [5.9687036e-01 3.9588490e-01 7.2447825e-03]\n",
      " [5.9074116e-01 1.2744847e-02 3.9651397e-01]\n",
      " [9.8732067e-03 9.8910940e-01 1.0174518e-03]\n",
      " [9.5320590e-02 6.7504698e-01 2.2963248e-01]\n",
      " [9.2178509e-02 6.0392190e-02 8.4742934e-01]\n",
      " [2.6121756e-04 8.3067029e-04 9.9890804e-01]]\n",
      "Predicted labels (argmax): [2 2 0 0 1 1 2 2]\n",
      "Step 65: Processing batch\n",
      "True labels (y_true): [1 2 2 0 1 0 0 1]\n",
      "Model predictions (raw): [[0.08056814 0.88759255 0.03183932]\n",
      " [0.08438509 0.0500336  0.8655813 ]\n",
      " [0.02944196 0.09290656 0.8776514 ]\n",
      " [0.9750265  0.02389574 0.0010778 ]\n",
      " [0.29856268 0.5559948  0.14544253]\n",
      " [0.62286055 0.37190753 0.00523194]\n",
      " [0.7912371  0.16131596 0.04744689]\n",
      " [0.05904949 0.9322862  0.00866433]]\n",
      "Predicted labels (argmax): [1 2 2 0 1 0 0 1]\n",
      "Step 66: Processing batch\n",
      "True labels (y_true): [0 1 0 1 1 0 0 1]\n",
      "Model predictions (raw): [[9.21233356e-01 4.95902710e-02 2.91764215e-02]\n",
      " [2.87236253e-05 9.99481142e-01 4.90142498e-04]\n",
      " [9.95943367e-01 2.87452899e-03 1.18207035e-03]\n",
      " [2.29460090e-01 6.68612599e-01 1.01927355e-01]\n",
      " [6.20383732e-02 9.15862560e-01 2.20990311e-02]\n",
      " [9.95837688e-01 3.70172039e-03 4.60639305e-04]\n",
      " [9.41238165e-01 4.43621539e-02 1.43997204e-02]\n",
      " [3.19336414e-01 3.57064992e-01 3.23598623e-01]]\n",
      "Predicted labels (argmax): [0 1 0 1 1 0 0 1]\n",
      "Step 67: Processing batch\n",
      "True labels (y_true): [0 0 2 2 0 1 2 1]\n",
      "Model predictions (raw): [[9.98614073e-01 1.12287409e-03 2.63090682e-04]\n",
      " [7.39254355e-01 2.39304855e-01 2.14408301e-02]\n",
      " [2.80451472e-03 3.63803725e-03 9.93557394e-01]\n",
      " [1.22690219e-02 2.94158468e-03 9.84789371e-01]\n",
      " [9.73165393e-01 2.04562377e-02 6.37838244e-03]\n",
      " [1.55454949e-01 8.44435096e-01 1.09919354e-04]\n",
      " [4.71642613e-02 1.24589577e-02 9.40376699e-01]\n",
      " [1.29652694e-01 6.75293028e-01 1.95054293e-01]]\n",
      "Predicted labels (argmax): [0 0 2 2 0 1 2 1]\n",
      "Step 68: Processing batch\n",
      "True labels (y_true): [0 2 2 1 0 0 1 1]\n",
      "Model predictions (raw): [[9.9508685e-01 1.7012031e-03 3.2120030e-03]\n",
      " [3.3330068e-02 1.9315982e-02 9.4735396e-01]\n",
      " [5.4877382e-02 5.2379696e-03 9.3988460e-01]\n",
      " [2.0721139e-02 9.5715404e-01 2.2124868e-02]\n",
      " [9.9089289e-01 7.1559199e-03 1.9511856e-03]\n",
      " [9.7212380e-01 1.4297397e-02 1.3578808e-02]\n",
      " [3.6973757e-04 9.9951792e-01 1.1229599e-04]\n",
      " [1.2173698e-01 8.4788007e-01 3.0383009e-02]]\n",
      "Predicted labels (argmax): [0 2 2 1 0 0 1 1]\n",
      "Step 69: Processing batch\n",
      "True labels (y_true): [2 0 2 0 2 1 0 0]\n",
      "Model predictions (raw): [[0.01601151 0.02114502 0.9628435 ]\n",
      " [0.98879856 0.00407718 0.00712426]\n",
      " [0.01006181 0.01326815 0.97667   ]\n",
      " [0.9306474  0.04249625 0.02685631]\n",
      " [0.05681958 0.03655476 0.90662575]\n",
      " [0.02908383 0.96675    0.00416608]\n",
      " [0.7299259  0.18790185 0.0821723 ]\n",
      " [0.9416625  0.04088395 0.0174536 ]]\n",
      "Predicted labels (argmax): [2 0 2 0 2 1 0 0]\n",
      "Step 70: Processing batch\n",
      "True labels (y_true): [0 0 0 1 1 1 0 1]\n",
      "Model predictions (raw): [[7.0704842e-01 6.7110822e-02 2.2584076e-01]\n",
      " [5.3182685e-01 1.5240716e-02 4.5293239e-01]\n",
      " [9.9936193e-01 6.3282147e-04 5.2259252e-06]\n",
      " [7.0160806e-02 9.0752292e-01 2.2316312e-02]\n",
      " [9.4182663e-02 6.5016156e-01 2.5565577e-01]\n",
      " [1.4706841e-03 9.9164963e-01 6.8796580e-03]\n",
      " [9.9986196e-01 9.2278919e-05 4.5775050e-05]\n",
      " [4.4563273e-03 9.9521446e-01 3.2926362e-04]]\n",
      "Predicted labels (argmax): [0 0 0 1 1 1 0 1]\n",
      "Step 71: Processing batch\n",
      "True labels (y_true): [1 2 2 1 1 2 2 2]\n",
      "Model predictions (raw): [[2.6208201e-02 9.7141236e-01 2.3794759e-03]\n",
      " [3.1502280e-02 7.7780001e-02 8.9071774e-01]\n",
      " [4.8209527e-03 6.5415301e-03 9.8863751e-01]\n",
      " [1.9062056e-01 7.8720719e-01 2.2172296e-02]\n",
      " [5.3193106e-04 9.9879539e-01 6.7268504e-04]\n",
      " [1.9325675e-02 6.6367984e-03 9.7403753e-01]\n",
      " [2.0415319e-02 1.3942671e-02 9.6564209e-01]\n",
      " [1.9086747e-04 2.4146591e-03 9.9739444e-01]]\n",
      "Predicted labels (argmax): [1 2 2 1 1 2 2 2]\n",
      "Step 72: Processing batch\n",
      "True labels (y_true): [1 2 1 1 0 0 1 1]\n",
      "Model predictions (raw): [[1.96821645e-01 3.24604750e-01 4.78573561e-01]\n",
      " [1.03427969e-01 1.02947570e-01 7.93624341e-01]\n",
      " [1.18131764e-01 8.55481803e-01 2.63864528e-02]\n",
      " [3.24932602e-03 9.93531764e-01 3.21896886e-03]\n",
      " [9.43882644e-01 4.36260812e-02 1.24912830e-02]\n",
      " [9.96558130e-01 3.21667548e-03 2.25112177e-04]\n",
      " [1.30011007e-01 8.51907253e-01 1.80817936e-02]\n",
      " [3.69434841e-02 9.41765130e-01 2.12914385e-02]]\n",
      "Predicted labels (argmax): [2 2 1 1 0 0 1 1]\n",
      "Step 73: Processing batch\n",
      "True labels (y_true): [1 1 1 0 0 2 0 1]\n",
      "Model predictions (raw): [[1.33588044e-02 9.85978544e-01 6.62586594e-04]\n",
      " [1.38307691e-01 3.99704218e-01 4.61988091e-01]\n",
      " [8.17794935e-05 9.99866128e-01 5.20866597e-05]\n",
      " [9.95075881e-01 3.80713982e-03 1.11699686e-03]\n",
      " [9.99985218e-01 1.45645445e-05 1.79978016e-07]\n",
      " [7.48402614e-04 4.63782111e-03 9.94613707e-01]\n",
      " [9.71725643e-01 1.38778868e-03 2.68866047e-02]\n",
      " [6.86277708e-05 9.99623179e-01 3.08172603e-04]]\n",
      "Predicted labels (argmax): [1 2 1 0 0 2 0 1]\n",
      "Step 74: Processing batch\n",
      "True labels (y_true): [2 0 0 1 1 1 1 2]\n",
      "Model predictions (raw): [[2.7065263e-03 1.3228769e-04 9.9716115e-01]\n",
      " [9.9762207e-01 1.6302691e-03 7.4772723e-04]\n",
      " [3.6972398e-01 5.6210297e-01 6.8172999e-02]\n",
      " [3.7679452e-02 8.0996120e-01 1.5235934e-01]\n",
      " [2.2915380e-02 9.7678804e-01 2.9653969e-04]\n",
      " [4.3566499e-02 9.4886458e-01 7.5689694e-03]\n",
      " [3.8114563e-02 9.5356697e-01 8.3184792e-03]\n",
      " [8.7920196e-02 7.7204004e-02 8.3487576e-01]]\n",
      "Predicted labels (argmax): [2 0 1 1 1 1 1 2]\n",
      "Step 75: Processing batch\n",
      "True labels (y_true): [0 2 1 2 0 0 2 2]\n",
      "Model predictions (raw): [[9.7557509e-01 2.4392422e-02 3.2545708e-05]\n",
      " [1.9171984e-01 5.1357013e-01 2.9471001e-01]\n",
      " [6.4931046e-03 9.7370583e-01 1.9801103e-02]\n",
      " [2.7304859e-04 6.5127690e-03 9.9321425e-01]\n",
      " [9.4986528e-01 3.5453938e-02 1.4680778e-02]\n",
      " [7.7366495e-01 1.6982347e-01 5.6511555e-02]\n",
      " [3.8222838e-02 2.4313699e-01 7.1864021e-01]\n",
      " [8.0165928e-03 3.7027840e-03 9.8828053e-01]]\n",
      "Predicted labels (argmax): [0 1 1 2 0 0 2 2]\n",
      "Step 76: Processing batch\n",
      "True labels (y_true): [1 0 1 2 1 1 2 2]\n",
      "Model predictions (raw): [[1.08809404e-01 8.89362633e-01 1.82800868e-03]\n",
      " [9.95129347e-01 4.64857928e-03 2.22114613e-04]\n",
      " [1.23524927e-02 9.85315204e-01 2.33234302e-03]\n",
      " [2.68248264e-02 2.14299783e-02 9.51745212e-01]\n",
      " [8.50552134e-03 9.53257620e-01 3.82368714e-02]\n",
      " [3.62904698e-01 6.28717303e-01 8.37797299e-03]\n",
      " [4.47497703e-02 4.06315811e-02 9.14618552e-01]\n",
      " [3.74296695e-01 1.66683897e-01 4.59019452e-01]]\n",
      "Predicted labels (argmax): [1 0 1 2 1 1 2 2]\n",
      "Step 77: Processing batch\n",
      "True labels (y_true): [2 2 1 0 1 1 0 0]\n",
      "Model predictions (raw): [[1.8016919e-02 1.6745541e-02 9.6523750e-01]\n",
      " [3.6181431e-02 3.8593709e-03 9.5995915e-01]\n",
      " [2.6132053e-02 9.7161859e-01 2.2493142e-03]\n",
      " [9.6419662e-01 1.6259881e-02 1.9543467e-02]\n",
      " [9.2089688e-04 9.9840182e-01 6.7734421e-04]\n",
      " [1.0782392e-02 9.6500123e-01 2.4216438e-02]\n",
      " [9.9898273e-01 1.0148532e-03 2.3235502e-06]\n",
      " [9.9135613e-01 3.8544440e-03 4.7894246e-03]]\n",
      "Predicted labels (argmax): [2 2 1 0 1 1 0 0]\n",
      "Step 78: Processing batch\n",
      "True labels (y_true): [2 0 1 1 0 2 2 1]\n",
      "Model predictions (raw): [[2.7759094e-03 5.0269328e-03 9.9219716e-01]\n",
      " [9.7186148e-01 2.1122947e-02 7.0156404e-03]\n",
      " [4.0356409e-02 9.4263989e-01 1.7003736e-02]\n",
      " [3.7367664e-02 9.5871514e-01 3.9172424e-03]\n",
      " [9.9343044e-01 8.6698454e-04 5.7025691e-03]\n",
      " [3.6240447e-02 6.1041329e-02 9.0271831e-01]\n",
      " [2.5337586e-02 2.1213224e-02 9.5344919e-01]\n",
      " [1.9712783e-01 9.7236179e-02 7.0563596e-01]]\n",
      "Predicted labels (argmax): [2 0 1 1 0 2 2 2]\n",
      "Step 79: Processing batch\n",
      "True labels (y_true): [0 0 2 2 2 0 0 2]\n",
      "Model predictions (raw): [[9.99537230e-01 4.18936805e-04 4.38801144e-05]\n",
      " [9.88270283e-01 9.06718988e-03 2.66247196e-03]\n",
      " [2.33032857e-03 6.60327226e-02 9.31636930e-01]\n",
      " [2.18875837e-02 1.80932786e-02 9.60019171e-01]\n",
      " [6.21096406e-04 3.07634976e-02 9.68615353e-01]\n",
      " [9.26020145e-01 5.89802526e-02 1.49996225e-02]\n",
      " [9.98693883e-01 1.30502542e-03 1.10749920e-06]\n",
      " [1.14647061e-01 1.87890917e-01 6.97462082e-01]]\n",
      "Predicted labels (argmax): [0 0 2 2 2 0 0 2]\n",
      "Step 80: Processing batch\n",
      "True labels (y_true): [1 2 1 2 0 0 2 0]\n",
      "Model predictions (raw): [[2.1270060e-03 9.9763298e-01 2.4001818e-04]\n",
      " [1.7347727e-02 1.1268896e-03 9.8152542e-01]\n",
      " [4.1339004e-05 9.9994373e-01 1.4875712e-05]\n",
      " [7.5423694e-03 6.9229538e-04 9.9176532e-01]\n",
      " [6.3283598e-01 3.5823643e-01 8.9275409e-03]\n",
      " [9.5143044e-01 4.4040538e-02 4.5290557e-03]\n",
      " [5.3778556e-03 1.5388047e-03 9.9308336e-01]\n",
      " [9.9809617e-01 1.7977941e-03 1.0601357e-04]]\n",
      "Predicted labels (argmax): [1 2 1 2 0 0 2 0]\n",
      "Step 81: Processing batch\n",
      "True labels (y_true): [2 1 0 0 2 1 1 1]\n",
      "Model predictions (raw): [[1.77474804e-02 1.26793804e-02 9.69573140e-01]\n",
      " [2.53455160e-04 9.99730408e-01 1.60788532e-05]\n",
      " [8.12793314e-01 5.10084778e-02 1.36198178e-01]\n",
      " [6.62196815e-01 1.14796095e-01 2.23007098e-01]\n",
      " [1.25943718e-03 2.14962661e-02 9.77244258e-01]\n",
      " [8.27040970e-02 1.16826303e-01 8.00469637e-01]\n",
      " [3.81073146e-03 9.95978594e-01 2.10635597e-04]\n",
      " [4.39404137e-03 9.81077492e-01 1.45284729e-02]]\n",
      "Predicted labels (argmax): [2 1 0 0 2 2 1 1]\n",
      "Step 82: Processing batch\n",
      "True labels (y_true): [0 0 2 0 2 1 2 1]\n",
      "Model predictions (raw): [[9.9371779e-01 3.7943786e-03 2.4877877e-03]\n",
      " [9.3653840e-01 2.3279893e-03 6.1133672e-02]\n",
      " [7.4577712e-02 7.8335598e-02 8.4708667e-01]\n",
      " [9.9681002e-01 2.9544476e-03 2.3554459e-04]\n",
      " [8.7910555e-02 4.2452917e-02 8.6963654e-01]\n",
      " [3.8829947e-01 2.3455098e-01 3.7714952e-01]\n",
      " [9.0399962e-03 1.5498841e-02 9.7546118e-01]\n",
      " [1.4264208e-01 6.1859024e-01 2.3876770e-01]]\n",
      "Predicted labels (argmax): [0 0 2 0 2 0 2 1]\n",
      "Step 83: Processing batch\n",
      "True labels (y_true): [0 0 0 1 2 0 0 2]\n",
      "Model predictions (raw): [[9.9624228e-01 2.8865121e-03 8.7127287e-04]\n",
      " [8.7669170e-01 8.2865134e-02 4.0443182e-02]\n",
      " [3.1357029e-01 5.3853631e-01 1.4789337e-01]\n",
      " [1.5755529e-02 9.7924083e-01 5.0035887e-03]\n",
      " [1.3055562e-02 2.3195369e-02 9.6374911e-01]\n",
      " [5.3908128e-01 1.1153357e-03 4.5980334e-01]\n",
      " [9.5232230e-01 3.0307982e-02 1.7369783e-02]\n",
      " [2.8848303e-02 6.2387162e-01 3.4728009e-01]]\n",
      "Predicted labels (argmax): [0 0 1 1 2 0 0 1]\n",
      "Step 84: Processing batch\n",
      "True labels (y_true): [0 2 1 0 1 1 0 2]\n",
      "Model predictions (raw): [[9.9177867e-01 8.2153846e-03 5.8647256e-06]\n",
      " [1.2050176e-01 3.0524188e-01 5.7425642e-01]\n",
      " [1.2540935e-03 9.9870455e-01 4.1368414e-05]\n",
      " [9.9923253e-01 7.4142130e-04 2.6129952e-05]\n",
      " [3.0754670e-03 9.8227745e-01 1.4647047e-02]\n",
      " [4.1412939e-03 9.8973083e-01 6.1279498e-03]\n",
      " [9.9935561e-01 5.8736693e-04 5.7082274e-05]\n",
      " [2.2077352e-02 1.8602375e-02 9.5932025e-01]]\n",
      "Predicted labels (argmax): [0 2 1 0 1 1 0 2]\n",
      "Step 85: Processing batch\n",
      "True labels (y_true): [2 2 0 0 0 2 2 2]\n",
      "Model predictions (raw): [[2.2963774e-04 5.6260857e-03 9.9414426e-01]\n",
      " [5.7456656e-03 1.0301612e-02 9.8395270e-01]\n",
      " [6.9964170e-01 2.5199428e-01 4.8364025e-02]\n",
      " [6.2570506e-01 1.7807372e-02 3.5648763e-01]\n",
      " [9.8543698e-01 1.4214089e-02 3.4884436e-04]\n",
      " [2.0304716e-03 2.4156431e-03 9.9555391e-01]\n",
      " [1.1888104e-04 2.8610278e-03 9.9702007e-01]\n",
      " [1.1040833e-02 3.7430408e-03 9.8521614e-01]]\n",
      "Predicted labels (argmax): [2 2 0 0 0 2 2 2]\n",
      "Step 86: Processing batch\n",
      "True labels (y_true): [2 1 2 1 1 1 2 2]\n",
      "Model predictions (raw): [[6.3480735e-03 5.8027757e-03 9.8784912e-01]\n",
      " [9.7435201e-03 9.8977321e-01 4.8332434e-04]\n",
      " [9.4027841e-04 1.1889621e-03 9.9787080e-01]\n",
      " [1.0537342e-04 9.9979967e-01 9.5010219e-05]\n",
      " [2.1464124e-02 9.7837538e-01 1.6050304e-04]\n",
      " [3.7764595e-04 9.9569738e-01 3.9249253e-03]\n",
      " [1.2293657e-02 1.2629102e-02 9.7507721e-01]\n",
      " [3.0372664e-03 1.2103426e-02 9.8485929e-01]]\n",
      "Predicted labels (argmax): [2 1 2 1 1 1 2 2]\n",
      "Step 87: Processing batch\n",
      "True labels (y_true): [2 0 1 2 0 1 2 0]\n",
      "Model predictions (raw): [[4.44912240e-02 2.44704857e-02 9.31038260e-01]\n",
      " [9.85059977e-01 2.69879890e-03 1.22411372e-02]\n",
      " [2.11286664e-04 9.99148607e-01 6.40135724e-04]\n",
      " [2.56695636e-02 9.63200349e-03 9.64698374e-01]\n",
      " [6.67170107e-01 1.17136575e-01 2.15693340e-01]\n",
      " [1.22742343e-03 9.96108830e-01 2.66372925e-03]\n",
      " [1.78826868e-03 2.75170291e-03 9.95460093e-01]\n",
      " [9.49811280e-01 4.77747656e-02 2.41395342e-03]]\n",
      "Predicted labels (argmax): [2 0 1 2 0 1 2 0]\n",
      "Step 88: Processing batch\n",
      "True labels (y_true): [2 0 1 1 1 2 1 0]\n",
      "Model predictions (raw): [[0.00989531 0.03649028 0.95361435]\n",
      " [0.8998875  0.06460482 0.03550772]\n",
      " [0.01417567 0.9830315  0.00279278]\n",
      " [0.04133075 0.8764062  0.08226302]\n",
      " [0.2877965  0.70415324 0.00805021]\n",
      " [0.43661582 0.24923544 0.31414878]\n",
      " [0.15761764 0.7741066  0.06827573]\n",
      " [0.9729793  0.00884034 0.01818038]]\n",
      "Predicted labels (argmax): [2 0 1 1 1 0 1 0]\n",
      "Step 89: Processing batch\n",
      "True labels (y_true): [1 0 2 1 1 0 2 2]\n",
      "Model predictions (raw): [[2.61032823e-02 9.69578862e-01 4.31792485e-03]\n",
      " [9.58415926e-01 3.90397087e-02 2.54438701e-03]\n",
      " [4.22689086e-03 1.50311384e-02 9.80741978e-01]\n",
      " [2.00642958e-01 6.73349559e-01 1.26007482e-01]\n",
      " [3.36274981e-01 6.31988108e-01 3.17369998e-02]\n",
      " [8.82699907e-01 1.16385445e-01 9.14573669e-04]\n",
      " [3.41790207e-02 1.47478869e-02 9.51073050e-01]\n",
      " [6.95647448e-02 2.99675971e-01 6.30759299e-01]]\n",
      "Predicted labels (argmax): [1 0 2 1 1 0 2 2]\n",
      "Step 90: Processing batch\n",
      "True labels (y_true): [2 1 1 1 0 2 0 0]\n",
      "Model predictions (raw): [[2.96523105e-02 2.99781989e-02 9.40369427e-01]\n",
      " [1.00889064e-01 8.71793747e-01 2.73171626e-02]\n",
      " [6.85907379e-02 9.14835691e-01 1.65735595e-02]\n",
      " [3.97589840e-02 8.59467030e-01 1.00773945e-01]\n",
      " [5.07041991e-01 6.15487583e-02 4.31409210e-01]\n",
      " [1.78153589e-01 5.46010077e-01 2.75836378e-01]\n",
      " [9.90744174e-01 8.43963493e-03 8.16227344e-04]\n",
      " [9.88616288e-01 1.13201151e-02 6.36955301e-05]]\n",
      "Predicted labels (argmax): [2 1 1 1 0 1 0 0]\n",
      "Step 91: Processing batch\n",
      "True labels (y_true): [0 0 1 1 1 1 0 0]\n",
      "Model predictions (raw): [[4.4266009e-01 3.3639801e-01 2.2094186e-01]\n",
      " [9.8762834e-01 4.7164313e-03 7.6552173e-03]\n",
      " [4.7687390e-03 9.9482614e-01 4.0506857e-04]\n",
      " [2.2931553e-01 7.0623106e-01 6.4453416e-02]\n",
      " [6.1596427e-03 9.8882806e-01 5.0123320e-03]\n",
      " [1.5371598e-03 9.9733388e-01 1.1290229e-03]\n",
      " [9.9876392e-01 1.2118449e-03 2.4305724e-05]\n",
      " [9.9716020e-01 2.8318528e-03 7.9061438e-06]]\n",
      "Predicted labels (argmax): [0 0 1 1 1 1 0 0]\n",
      "Step 92: Processing batch\n",
      "True labels (y_true): [1 1 2 0 2 1 1 0]\n",
      "Model predictions (raw): [[6.5811343e-02 9.3357706e-01 6.1157928e-04]\n",
      " [5.8423877e-03 9.9005669e-01 4.1009141e-03]\n",
      " [9.2432281e-04 2.9243617e-03 9.9615127e-01]\n",
      " [9.1017789e-01 2.1140344e-02 6.8681814e-02]\n",
      " [2.3944618e-02 4.0099709e-03 9.7204554e-01]\n",
      " [1.9627729e-04 9.9958807e-01 2.1560831e-04]\n",
      " [5.6638669e-02 9.3617362e-01 7.1876771e-03]\n",
      " [7.0520031e-01 2.7944210e-01 1.5357629e-02]]\n",
      "Predicted labels (argmax): [1 1 2 0 2 1 1 0]\n",
      "Step 93: Processing batch\n",
      "True labels (y_true): [0 0 1 1 1 1 0 1]\n",
      "Model predictions (raw): [[7.1243644e-01 9.8952956e-02 1.8861054e-01]\n",
      " [9.7090530e-01 2.8298518e-02 7.9621270e-04]\n",
      " [5.9138913e-02 9.0322673e-01 3.7634324e-02]\n",
      " [1.0175438e-02 9.8971772e-01 1.0683655e-04]\n",
      " [8.9471951e-02 6.6561574e-01 2.4491230e-01]\n",
      " [2.3031621e-03 9.9366945e-01 4.0274481e-03]\n",
      " [4.2257968e-01 5.3008300e-01 4.7337301e-02]\n",
      " [1.6421045e-01 7.8987157e-01 4.5918014e-02]]\n",
      "Predicted labels (argmax): [0 0 1 1 1 1 1 1]\n",
      "Step 94: Processing batch\n",
      "True labels (y_true): [1 1 2 1 0 0 1 2]\n",
      "Model predictions (raw): [[1.4284824e-06 9.9999666e-01 1.9500251e-06]\n",
      " [4.7823428e-03 9.8325861e-01 1.1958988e-02]\n",
      " [2.5301096e-03 9.5179714e-03 9.8795193e-01]\n",
      " [8.3061041e-06 9.9997604e-01 1.5610854e-05]\n",
      " [9.9793220e-01 6.5178756e-04 1.4160033e-03]\n",
      " [7.8563416e-01 8.1029400e-02 1.3333647e-01]\n",
      " [3.0660339e-02 9.6912509e-01 2.1462400e-04]\n",
      " [4.3001663e-02 2.4838408e-02 9.3215984e-01]]\n",
      "Predicted labels (argmax): [1 1 2 1 0 0 1 2]\n",
      "Step 95: Processing batch\n",
      "True labels (y_true): [1 0 2 0 2 0 1 2]\n",
      "Model predictions (raw): [[3.0530307e-01 4.6832514e-01 2.2637177e-01]\n",
      " [9.9760348e-01 2.3041645e-03 9.2381568e-05]\n",
      " [5.4581338e-03 1.2535821e-02 9.8200607e-01]\n",
      " [6.9597560e-01 2.4641389e-01 5.7610445e-02]\n",
      " [5.6865723e-03 1.4847337e-02 9.7946608e-01]\n",
      " [9.6452934e-01 2.6562374e-02 8.9082038e-03]\n",
      " [1.0182213e-02 9.7830373e-01 1.1514051e-02]\n",
      " [1.4557739e-02 1.5021720e-02 9.7042060e-01]]\n",
      "Predicted labels (argmax): [1 0 2 0 2 0 1 2]\n",
      "Step 96: Processing batch\n",
      "True labels (y_true): [0 1 1 2 0 0 2 0]\n",
      "Model predictions (raw): [[9.38133955e-01 4.20132428e-02 1.98527835e-02]\n",
      " [7.53525738e-03 9.56998885e-01 3.54658701e-02]\n",
      " [4.06167019e-05 9.99855638e-01 1.03704115e-04]\n",
      " [1.63325623e-01 1.85668364e-01 6.51005983e-01]\n",
      " [9.09493446e-01 5.96329197e-02 3.08737252e-02]\n",
      " [9.81215298e-01 1.15157487e-02 7.26900948e-03]\n",
      " [1.28117041e-04 1.56055510e-04 9.99715865e-01]\n",
      " [8.06020319e-01 3.24084982e-02 1.61571175e-01]]\n",
      "Predicted labels (argmax): [0 1 1 2 0 0 2 0]\n",
      "Step 97: Processing batch\n",
      "True labels (y_true): [0 1 1 1 1 0 0 0]\n",
      "Model predictions (raw): [[9.6736723e-01 1.5355837e-02 1.7277028e-02]\n",
      " [1.4857665e-03 9.9847156e-01 4.2657914e-05]\n",
      " [4.5655526e-02 9.4005555e-01 1.4288985e-02]\n",
      " [3.7903935e-02 9.3971330e-01 2.2382747e-02]\n",
      " [3.8345784e-04 9.9760973e-01 2.0067741e-03]\n",
      " [9.6601516e-01 3.3446722e-02 5.3808407e-04]\n",
      " [7.3611778e-01 9.8048456e-02 1.6583377e-01]\n",
      " [4.3128136e-01 5.1148437e-02 5.1757026e-01]]\n",
      "Predicted labels (argmax): [0 1 1 1 1 0 0 2]\n",
      "Step 98: Processing batch\n",
      "True labels (y_true): [2 1 2 1 1 0 0 2]\n",
      "Model predictions (raw): [[5.68537216e-04 5.34495199e-03 9.94086504e-01]\n",
      " [2.60076398e-04 9.99206483e-01 5.33437531e-04]\n",
      " [2.86714006e-02 4.52378169e-02 9.26090777e-01]\n",
      " [7.69676417e-02 8.75405133e-01 4.76272181e-02]\n",
      " [3.14983204e-02 9.64513898e-01 3.98774398e-03]\n",
      " [9.99803960e-01 1.05828476e-04 9.02801476e-05]\n",
      " [9.80359077e-01 1.94696486e-02 1.71291322e-04]\n",
      " [8.92597884e-02 1.14792734e-02 8.99260938e-01]]\n",
      "Predicted labels (argmax): [2 1 2 1 1 0 0 2]\n",
      "Step 99: Processing batch\n",
      "True labels (y_true): [2 2 2 1 1 0 2 0]\n",
      "Model predictions (raw): [[5.7782698e-03 2.9933730e-02 9.6428794e-01]\n",
      " [2.1623206e-01 4.9547145e-01 2.8829652e-01]\n",
      " [3.5258945e-02 2.5817377e-02 9.3892366e-01]\n",
      " [1.4115848e-01 4.9137127e-01 3.6747026e-01]\n",
      " [1.7227086e-03 9.9529076e-01 2.9865927e-03]\n",
      " [9.8938900e-01 1.0525515e-02 8.5451276e-05]\n",
      " [1.4060361e-02 4.7406252e-03 9.8119903e-01]\n",
      " [9.9988055e-01 9.3139846e-05 2.6328256e-05]]\n",
      "Predicted labels (argmax): [2 1 2 1 1 0 2 0]\n",
      "Precision: 0.9522320646972645\n",
      "Recall: 0.9519066407434041\n",
      "F1 Score: 0.9519280802404944\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained your model and have the test_dataset ready\n",
    "# Make predictions on the test dataset\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate over the test dataset and make predictions\n",
    "for step, (images, labels) in enumerate(test_dataset):\n",
    "    print(f\"Step {step+1}: Processing batch\")\n",
    "\n",
    "    # True labels (ground truth)\n",
    "    y_true.extend(labels.numpy())\n",
    "    print(f\"True labels (y_true): {labels.numpy()}\")\n",
    "\n",
    "    # Model predictions\n",
    "    predictions = model(images, training=False)\n",
    "    print(f\"Model predictions (raw): {predictions.numpy()}\")\n",
    "\n",
    "    # Get the class with the highest score\n",
    "    predicted_labels = tf.argmax(predictions, axis=-1)\n",
    "    print(f\"Predicted labels (argmax): {predicted_labels.numpy()}\")\n",
    "\n",
    "    # Store predicted labels\n",
    "    y_pred.extend(predicted_labels.numpy())\n",
    "\n",
    "# Calculate Precision, Recall, and F1 score using sklearn\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Use 'micro', 'macro', or 'weighted' depending on your needs\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # Use 'micro', 'macro', or 'weighted' depending on your needs\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # Calculate F1 score\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
